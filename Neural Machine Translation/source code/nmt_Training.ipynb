{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Reference]\n",
    "Tensorflow(2020.11) nmt_with_attention[Source Code]\n",
    "https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tutorials/text/nmt_with_attention.ipynb\n",
    "Building models for NMT\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6C5I92usDlWa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13726352853067687357\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12775957749617462132\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11991246439\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8952938922944189331\n",
      "physical_device_desc: \"device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12889262038508714768\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2LGie5tSDrLl"
   },
   "outputs": [],
   "source": [
    "path_to_file_esb = '../dataset/train/spa-eng/spa_for_esb.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wCTS3Es_EJl-"
   },
   "outputs": [],
   "source": [
    "# 유니코드 파일을 아스키 코드 파일로 변환합니다.\n",
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "  w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "  # 단어와 단어 뒤에 오는 구두점(.)사이에 공백을 생성합니다.\n",
    "  # 예시: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # 참고:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")을 제외한 모든 것을 공백으로 대체합니다.\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # 모델이 예측을 시작하거나 중단할 때를 알게 하기 위해서\n",
    "  # 문장에 start와 end 토큰을 추가합니다.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 생성\n",
    "1. 문장에 있는 억양을 제거합니다.\n",
    "2. 불필요한 문자를 제거하여 문장을 정리합니다.\n",
    "3. 다음과 같은 형식으로 문장의 쌍을 반환합니다: [영어, 스페인어]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3VXgr4_2EUgt"
   },
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language 가 들어오면 공백 단위로 토큰화\n",
    "- fit_on_texts(): 문자 데이터를 입력받아서 리스트의 형태로 변환\n",
    "- texts_to_sequences: 텍스트 안의 단어들을 숫자 시퀀스로 출력\n",
    "- pad_sequcences(tensor, padding='post') : 서로 다른 개수의 단어로 이루어진 문장을 같은 길이로 만들어주기 위해 패딩을 사용\n",
    "  - padding = 'post' : [[ 0  0  0  5  3  2  4], [ 0  0  0  5  3  2  7],...,]\n",
    "  - padding = 'pre' : 뒤 부터 패딩이 채워짐\n",
    "  - 가장 긴 sequence 의 길이 만큼\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "u9VUFvjLEdER"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **전처리된 타겟 문장과 입력 문장 쌍을 생성**\n",
    "- input_tensor : input 문장의 패딩 처리된 숫자 시퀀스\n",
    "- inp_lang_tokenizer : input 문장을 공백 단위로 토큰화, 문자 -> 리스트 변환\n",
    "- target_tensor, targ_lang_tokenizer : 위와 비슷\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Rc4Rbx8JEjQZ"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "\n",
    "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 언어 데이터셋 크기 제한\n",
    "- 언어 데이터셋을 아래의 크기로 제한하여 훈련과 검증을 수행\n",
    "- inp_lang, targ_lang : 인풋,타겟 문장의 문자 -> 리스트 변환 결과\n",
    "- max_length_targ, max_length_inp : 인풋, 타겟 문장의 '패딩된' 숫자 시퀀스 길이 -> 타겟 텐서와 입력 텐서의 최대 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ioibz-1bEkx-"
   },
   "outputs": [],
   "source": [
    "num_examples = 60000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file_esb, num_examples)\n",
    "\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 (테스트 & 검증) 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VAt188iPEpFc",
    "outputId": "a7f39378-50a8-4f42-fff7-c99938f0d5e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 48000 12000 12000\n"
     ]
    }
   ],
   "source": [
    "# 훈련 집합과 검증 집합을 80대 20으로 분리합니다.\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# 훈련 집합과 검증 집합의 데이터 크기를 출력합니다.\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인덱스 -> 해당 word 로\n",
    "\n",
    "```\n",
    "Input Language; index to word mapping\n",
    "1 ----> <start>\n",
    "93 ----> tomas\n",
    "27 ----> le\n",
    "1063 ----> escribio\n",
    "7 ----> a\n",
    "120 ----> maria\n",
    "3 ----> .\n",
    "2 ----> <end>\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "Target Language; index to word mapping\n",
    "1 ----> <start>\n",
    "8 ----> tom\n",
    "695 ----> wrote\n",
    "6 ----> to\n",
    "31 ----> mary\n",
    "3 ----> .\n",
    "2 ----> <end>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XwDUP11tErzK"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buffer, Batch, epoch, embedding dimension, units 설정\n",
    "- Tokenizer 의 word_index 속성 : 속성은 단어와 숫자의 키-값 쌍을 포함하는 딕셔너리를 반환\n",
    "- 따라서 vocab_inp_size, vocab_inp_size : 인풋, 타겟의 단어-숫자 딕셔너리 최대 길이 + 1 (?)\n",
    "- dataset.batch(BATCH_SIZE, drop_remainder = True) : 배치사이즈 만큼 분할 후 남은 데이터를 drop 할 것인지 여부\n",
    "- shuffle : 데이터셋 적절히 섞어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hU7tb2GYEvZX"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1777jlZSE5mz",
    "outputId": "5e498e12-0b82-4b62-e845-c930a6c44052"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 53]), TensorShape([64, 51]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder\n",
    "\n",
    "1.   초기화 : vocab_size(단어의 크기), embedding_dim(임베딩 차원 수), enc_units(인코더의 히든 사이즈), batch_sz(배치 사이즈)\n",
    "  - embedding_dim : 단어 -> 임베딩 벡터로 하기 위한 차원 수\n",
    "2.  call : gru 에 들어가 output, state 출력\n",
    "3.  initialize_hidden_state : 맨 처음 gru에 들어가기 위한 더미 입력 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AvYcCHoFE7UY"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsoTBEKRFgkQ",
    "outputId": "5c4d0089-d314-4c28-c5cb-53a390517cce"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2T7avh_BFVZN"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # 쿼리 은닉 상태(query hidden state)는 (batch_size, hidden size)쌍으로 이루어져 있습니다.\n",
    "    # query_with_time_axis은 (batch_size, 1, hidden size)쌍으로 이루어져 있습니다.\n",
    "    # values는 (batch_size, max_len, hidden size)쌍으로 이루어져 있습니다.\n",
    "    # 스코어(score)계산을 위해 덧셈을 수행하고자 시간 축을 확장하여 아래의 과정을 수행합니다.\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score는 (batch_size, max_length, 1)쌍으로 이루어져 있습니다.\n",
    "    # score를 self.V에 적용하기 때문에 마지막 축에 1을 얻습니다.\n",
    "    # self.V에 적용하기 전에 텐서는 (batch_size, max_length, units)쌍으로 이루어져 있습니다.\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights는 (batch_size, max_length, 1)쌍으로 이루어져 있습니다. \n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # 덧셈이후 컨텍스트 벡터(context_vector)는 (batch_size, hidden_size)쌍으로 이루어져 있습니다.\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder\n",
    "\n",
    "1.   초기화 : vocab_size(단어의 크기), embedding_dim(임베딩 차원 수), enc_units(인코더의 히든 사이즈), batch_sz(배치 사이즈)\n",
    "2.   encoder 와의 차이점 : 마지막 fully_connected_layer(tf.keras.layers.Dense) 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "weUzeqB1FaVk"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # 어텐션을 사용합니다.\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output는 (batch_size, max_length, hidden_size)쌍으로 이루어져 있습니다.\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # 임베딩층을 통과한 후 x는 (batch_size, 1, embedding_dim)쌍으로 이루어져 있습니다.\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # 컨텍스트 벡터와 임베딩 결과를 결합한 이후 x의 형태는 (batch_size, 1, embedding_dim + hidden_size)쌍으로 이루어져 있습니다.\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # 위에서 결합된 벡터를 GRU에 전달합니다.\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output은 (batch_size * 1, hidden_size)쌍으로 이루어져 있습니다.\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output은 (batch_size, vocab)쌍으로 이루어져 있습니다.\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NoeGR2CsFk8E",
    "outputId": "7fad08c3-cae3-4867-dfe8-7668782ee726"
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "QFs5xbUXFmPH"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chekcpoint\n",
    "- 여기서 학습한 매개변수를 저장, optimizer/encoder/decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Z7GWRTtRFoGz"
   },
   "outputs": [],
   "source": [
    "# 각각의 모델 번역 확인을 위해서 (각각 다른 모델 체크포인트)\n",
    "checkpoint_dir = '../Checkpoint_super/training_checkpoints2'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ydveA1RlFp8u"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # 교사 강요(teacher forcing) - 다음 입력으로 타겟을 피딩(feeding)합니다.\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # enc_output를 디코더에 전달합니다.\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # 교사 강요(teacher forcing)를 사용합니다.\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1KizVpKbFst7",
    "outputId": "daecdc04-c4ad-4a7f-d67b-381d0a9edd16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.3641\n",
      "Epoch 1 Batch 100 Loss 0.3282\n",
      "Epoch 1 Batch 200 Loss 0.3358\n",
      "Epoch 1 Batch 300 Loss 0.4030\n",
      "Epoch 1 Batch 400 Loss 0.2950\n",
      "Epoch 1 Batch 500 Loss 0.3961\n",
      "Epoch 1 Batch 600 Loss 0.3444\n",
      "Epoch 1 Batch 700 Loss 0.3490\n",
      "Epoch 1 Loss 0.3331\n",
      "Time taken for 1 epoch 237.2544116973877 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.2188\n",
      "Epoch 2 Batch 100 Loss 0.2404\n",
      "Epoch 2 Batch 200 Loss 0.2347\n",
      "Epoch 2 Batch 300 Loss 0.2005\n",
      "Epoch 2 Batch 400 Loss 0.2429\n",
      "Epoch 2 Batch 500 Loss 0.2398\n",
      "Epoch 2 Batch 600 Loss 0.2452\n",
      "Epoch 2 Batch 700 Loss 0.2208\n",
      "Epoch 2 Loss 0.2455\n",
      "Time taken for 1 epoch 239.80951380729675 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.1664\n",
      "Epoch 3 Batch 100 Loss 0.1472\n",
      "Epoch 3 Batch 200 Loss 0.2362\n",
      "Epoch 3 Batch 300 Loss 0.1789\n",
      "Epoch 3 Batch 400 Loss 0.1870\n",
      "Epoch 3 Batch 500 Loss 0.1885\n",
      "Epoch 3 Batch 600 Loss 0.1873\n",
      "Epoch 3 Batch 700 Loss 0.2284\n",
      "Epoch 3 Loss 0.1844\n",
      "Time taken for 1 epoch 239.42481112480164 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.1136\n",
      "Epoch 4 Batch 100 Loss 0.1115\n",
      "Epoch 4 Batch 200 Loss 0.1161\n",
      "Epoch 4 Batch 300 Loss 0.1484\n",
      "Epoch 4 Batch 400 Loss 0.1519\n",
      "Epoch 4 Batch 500 Loss 0.1499\n",
      "Epoch 4 Batch 600 Loss 0.1166\n",
      "Epoch 4 Batch 700 Loss 0.1541\n",
      "Epoch 4 Loss 0.1400\n",
      "Time taken for 1 epoch 239.41186022758484 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.1049\n",
      "Epoch 5 Batch 100 Loss 0.0930\n",
      "Epoch 5 Batch 200 Loss 0.1213\n",
      "Epoch 5 Batch 300 Loss 0.1125\n",
      "Epoch 5 Batch 400 Loss 0.1371\n",
      "Epoch 5 Batch 500 Loss 0.1222\n",
      "Epoch 5 Batch 600 Loss 0.1191\n",
      "Epoch 5 Batch 700 Loss 0.1192\n",
      "Epoch 5 Loss 0.1097\n",
      "Time taken for 1 epoch 238.71830797195435 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0805\n",
      "Epoch 6 Batch 100 Loss 0.0671\n",
      "Epoch 6 Batch 200 Loss 0.1048\n",
      "Epoch 6 Batch 300 Loss 0.0937\n",
      "Epoch 6 Batch 400 Loss 0.1145\n",
      "Epoch 6 Batch 500 Loss 0.0819\n",
      "Epoch 6 Batch 600 Loss 0.1013\n",
      "Epoch 6 Batch 700 Loss 0.0859\n",
      "Epoch 6 Loss 0.0871\n",
      "Time taken for 1 epoch 239.72337746620178 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0802\n",
      "Epoch 7 Batch 100 Loss 0.0646\n",
      "Epoch 7 Batch 200 Loss 0.0657\n",
      "Epoch 7 Batch 300 Loss 0.0618\n",
      "Epoch 7 Batch 400 Loss 0.0602\n",
      "Epoch 7 Batch 500 Loss 0.0755\n",
      "Epoch 7 Batch 600 Loss 0.0685\n",
      "Epoch 7 Batch 700 Loss 0.0771\n",
      "Epoch 7 Loss 0.0696\n",
      "Time taken for 1 epoch 241.05693936347961 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0532\n",
      "Epoch 8 Batch 100 Loss 0.0536\n",
      "Epoch 8 Batch 200 Loss 0.0618\n",
      "Epoch 8 Batch 300 Loss 0.0423\n",
      "Epoch 8 Batch 400 Loss 0.0533\n",
      "Epoch 8 Batch 500 Loss 0.0465\n",
      "Epoch 8 Batch 600 Loss 0.0659\n",
      "Epoch 8 Batch 700 Loss 0.0503\n",
      "Epoch 8 Loss 0.0568\n",
      "Time taken for 1 epoch 240.35404682159424 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0470\n",
      "Epoch 9 Batch 100 Loss 0.0380\n",
      "Epoch 9 Batch 200 Loss 0.0488\n",
      "Epoch 9 Batch 300 Loss 0.0542\n",
      "Epoch 9 Batch 400 Loss 0.0515\n",
      "Epoch 9 Batch 500 Loss 0.0454\n",
      "Epoch 9 Batch 600 Loss 0.0448\n",
      "Epoch 9 Batch 700 Loss 0.0410\n",
      "Epoch 9 Loss 0.0475\n",
      "Time taken for 1 epoch 240.17695426940918 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0341\n",
      "Epoch 10 Batch 100 Loss 0.0294\n",
      "Epoch 10 Batch 200 Loss 0.0265\n",
      "Epoch 10 Batch 300 Loss 0.0356\n",
      "Epoch 10 Batch 400 Loss 0.0405\n",
      "Epoch 10 Batch 500 Loss 0.0433\n",
      "Epoch 10 Batch 600 Loss 0.0397\n",
      "Epoch 10 Batch 700 Loss 0.0583\n",
      "Epoch 10 Loss 0.0374\n",
      "Time taken for 1 epoch 240.32441449165344 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0262\n",
      "Epoch 11 Batch 100 Loss 0.0292\n",
      "Epoch 11 Batch 200 Loss 0.0260\n",
      "Epoch 11 Batch 300 Loss 0.0257\n",
      "Epoch 11 Batch 400 Loss 0.0315\n",
      "Epoch 11 Batch 500 Loss 0.0262\n",
      "Epoch 11 Batch 600 Loss 0.0420\n",
      "Epoch 11 Batch 700 Loss 0.0354\n",
      "Epoch 11 Loss 0.0303\n",
      "Time taken for 1 epoch 239.26266193389893 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0294\n",
      "Epoch 12 Batch 100 Loss 0.0221\n",
      "Epoch 12 Batch 200 Loss 0.0246\n",
      "Epoch 12 Batch 300 Loss 0.0224\n",
      "Epoch 12 Batch 400 Loss 0.0245\n",
      "Epoch 12 Batch 500 Loss 0.0303\n",
      "Epoch 12 Batch 600 Loss 0.0220\n",
      "Epoch 12 Batch 700 Loss 0.0282\n",
      "Epoch 12 Loss 0.0266\n",
      "Time taken for 1 epoch 239.14594078063965 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0158\n",
      "Epoch 13 Batch 100 Loss 0.0219\n",
      "Epoch 13 Batch 200 Loss 0.0168\n",
      "Epoch 13 Batch 300 Loss 0.0290\n",
      "Epoch 13 Batch 400 Loss 0.0268\n",
      "Epoch 13 Batch 500 Loss 0.0230\n",
      "Epoch 13 Batch 600 Loss 0.0369\n",
      "Epoch 13 Batch 700 Loss 0.0282\n",
      "Epoch 13 Loss 0.0265\n",
      "Time taken for 1 epoch 239.82417249679565 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0323\n",
      "Epoch 14 Batch 100 Loss 0.0296\n",
      "Epoch 14 Batch 200 Loss 0.0332\n",
      "Epoch 14 Batch 300 Loss 0.0389\n",
      "Epoch 14 Batch 400 Loss 0.0292\n",
      "Epoch 14 Batch 500 Loss 0.0243\n",
      "Epoch 14 Batch 600 Loss 0.0280\n",
      "Epoch 14 Batch 700 Loss 0.0362\n",
      "Epoch 14 Loss 0.0285\n",
      "Time taken for 1 epoch 239.39956879615784 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0142\n",
      "Epoch 15 Batch 100 Loss 0.0178\n",
      "Epoch 15 Batch 200 Loss 0.0200\n",
      "Epoch 15 Batch 300 Loss 0.0333\n",
      "Epoch 15 Batch 400 Loss 0.0380\n",
      "Epoch 15 Batch 500 Loss 0.0315\n",
      "Epoch 15 Batch 600 Loss 0.0290\n",
      "Epoch 15 Batch 700 Loss 0.0415\n",
      "Epoch 15 Loss 0.0283\n",
      "Time taken for 1 epoch 238.70186495780945 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0158\n",
      "Epoch 16 Batch 100 Loss 0.0172\n",
      "Epoch 16 Batch 200 Loss 0.0168\n",
      "Epoch 16 Batch 300 Loss 0.0173\n",
      "Epoch 16 Batch 400 Loss 0.0162\n",
      "Epoch 16 Batch 500 Loss 0.0258\n",
      "Epoch 16 Batch 600 Loss 0.0180\n",
      "Epoch 16 Batch 700 Loss 0.0181\n",
      "Epoch 16 Loss 0.0196\n",
      "Time taken for 1 epoch 240.37423872947693 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0152\n",
      "Epoch 17 Batch 100 Loss 0.0093\n",
      "Epoch 17 Batch 200 Loss 0.0192\n",
      "Epoch 17 Batch 300 Loss 0.0201\n",
      "Epoch 17 Batch 400 Loss 0.0134\n",
      "Epoch 17 Batch 500 Loss 0.0138\n",
      "Epoch 17 Batch 600 Loss 0.0138\n",
      "Epoch 17 Batch 700 Loss 0.0214\n",
      "Epoch 17 Loss 0.0156\n",
      "Time taken for 1 epoch 239.24288368225098 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0140\n",
      "Epoch 18 Batch 100 Loss 0.0197\n",
      "Epoch 18 Batch 200 Loss 0.0115\n",
      "Epoch 18 Batch 300 Loss 0.0104\n",
      "Epoch 18 Batch 400 Loss 0.0120\n",
      "Epoch 18 Batch 500 Loss 0.0163\n",
      "Epoch 18 Batch 600 Loss 0.0150\n",
      "Epoch 18 Batch 700 Loss 0.0115\n",
      "Epoch 18 Loss 0.0140\n",
      "Time taken for 1 epoch 240.51381969451904 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0113\n",
      "Epoch 19 Batch 100 Loss 0.0111\n",
      "Epoch 19 Batch 200 Loss 0.0143\n",
      "Epoch 19 Batch 300 Loss 0.0160\n",
      "Epoch 19 Batch 400 Loss 0.0111\n",
      "Epoch 19 Batch 500 Loss 0.0260\n",
      "Epoch 19 Batch 600 Loss 0.0232\n",
      "Epoch 19 Batch 700 Loss 0.0268\n",
      "Epoch 19 Loss 0.0162\n",
      "Time taken for 1 epoch 239.57410073280334 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0147\n",
      "Epoch 20 Batch 100 Loss 0.0162\n",
      "Epoch 20 Batch 200 Loss 0.0155\n",
      "Epoch 20 Batch 300 Loss 0.0212\n",
      "Epoch 20 Batch 400 Loss 0.0266\n",
      "Epoch 20 Batch 500 Loss 0.0206\n",
      "Epoch 20 Batch 600 Loss 0.0307\n",
      "Epoch 20 Batch 700 Loss 0.0301\n",
      "Epoch 20 Loss 0.0212\n",
      "Time taken for 1 epoch 240.10835456848145 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0188\n",
      "Epoch 21 Batch 100 Loss 0.0289\n",
      "Epoch 21 Batch 200 Loss 0.0142\n",
      "Epoch 21 Batch 300 Loss 0.0110\n",
      "Epoch 21 Batch 400 Loss 0.0161\n",
      "Epoch 21 Batch 500 Loss 0.0203\n",
      "Epoch 21 Batch 600 Loss 0.0385\n",
      "Epoch 21 Batch 700 Loss 0.0181\n",
      "Epoch 21 Loss 0.0183\n",
      "Time taken for 1 epoch 240.09661674499512 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0163\n",
      "Epoch 22 Batch 100 Loss 0.0127\n",
      "Epoch 22 Batch 200 Loss 0.0084\n",
      "Epoch 22 Batch 300 Loss 0.0132\n",
      "Epoch 22 Batch 400 Loss 0.0160\n",
      "Epoch 22 Batch 500 Loss 0.0122\n",
      "Epoch 22 Batch 600 Loss 0.0145\n",
      "Epoch 22 Batch 700 Loss 0.0224\n",
      "Epoch 22 Loss 0.0139\n",
      "Time taken for 1 epoch 240.63825345039368 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0108\n",
      "Epoch 23 Batch 100 Loss 0.0137\n",
      "Epoch 23 Batch 200 Loss 0.0114\n",
      "Epoch 23 Batch 300 Loss 0.0108\n",
      "Epoch 23 Batch 400 Loss 0.0147\n",
      "Epoch 23 Batch 500 Loss 0.0123\n",
      "Epoch 23 Batch 600 Loss 0.0148\n",
      "Epoch 23 Batch 700 Loss 0.0141\n",
      "Epoch 23 Loss 0.0131\n",
      "Time taken for 1 epoch 240.2110743522644 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0104\n",
      "Epoch 24 Batch 100 Loss 0.0064\n",
      "Epoch 24 Batch 200 Loss 0.0095\n",
      "Epoch 24 Batch 300 Loss 0.0068\n",
      "Epoch 24 Batch 400 Loss 0.0172\n",
      "Epoch 24 Batch 500 Loss 0.0070\n",
      "Epoch 24 Batch 600 Loss 0.0127\n",
      "Epoch 24 Batch 700 Loss 0.0151\n",
      "Epoch 24 Loss 0.0111\n",
      "Time taken for 1 epoch 239.24461007118225 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0099\n",
      "Epoch 25 Batch 100 Loss 0.0153\n",
      "Epoch 25 Batch 200 Loss 0.0088\n",
      "Epoch 25 Batch 300 Loss 0.0079\n",
      "Epoch 25 Batch 400 Loss 0.0087\n",
      "Epoch 25 Batch 500 Loss 0.0098\n",
      "Epoch 25 Batch 600 Loss 0.0190\n",
      "Epoch 25 Batch 700 Loss 0.0135\n",
      "Epoch 25 Loss 0.0117\n",
      "Time taken for 1 epoch 240.3700532913208 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.0079\n",
      "Epoch 26 Batch 100 Loss 0.0111\n",
      "Epoch 26 Batch 200 Loss 0.0075\n",
      "Epoch 26 Batch 300 Loss 0.0096\n",
      "Epoch 26 Batch 400 Loss 0.0157\n",
      "Epoch 26 Batch 500 Loss 0.0156\n",
      "Epoch 26 Batch 600 Loss 0.0205\n",
      "Epoch 26 Batch 700 Loss 0.0282\n",
      "Epoch 26 Loss 0.0163\n",
      "Time taken for 1 epoch 239.88684964179993 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.0135\n",
      "Epoch 27 Batch 100 Loss 0.0153\n",
      "Epoch 27 Batch 200 Loss 0.0082\n",
      "Epoch 27 Batch 300 Loss 0.0159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 400 Loss 0.0143\n",
      "Epoch 27 Batch 500 Loss 0.0143\n",
      "Epoch 27 Batch 600 Loss 0.0158\n",
      "Epoch 27 Batch 700 Loss 0.0171\n",
      "Epoch 27 Loss 0.0133\n",
      "Time taken for 1 epoch 240.39121079444885 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.0105\n",
      "Epoch 28 Batch 100 Loss 0.0075\n",
      "Epoch 28 Batch 200 Loss 0.0057\n",
      "Epoch 28 Batch 300 Loss 0.0066\n",
      "Epoch 28 Batch 400 Loss 0.0122\n",
      "Epoch 28 Batch 500 Loss 0.0153\n",
      "Epoch 28 Batch 600 Loss 0.0111\n",
      "Epoch 28 Batch 700 Loss 0.0182\n",
      "Epoch 28 Loss 0.0107\n",
      "Time taken for 1 epoch 239.46493077278137 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.0080\n",
      "Epoch 29 Batch 100 Loss 0.0086\n",
      "Epoch 29 Batch 200 Loss 0.0058\n",
      "Epoch 29 Batch 300 Loss 0.0171\n",
      "Epoch 29 Batch 400 Loss 0.0154\n",
      "Epoch 29 Batch 500 Loss 0.0216\n",
      "Epoch 29 Batch 600 Loss 0.0119\n",
      "Epoch 29 Batch 700 Loss 0.0170\n",
      "Epoch 29 Loss 0.0145\n",
      "Time taken for 1 epoch 239.05121898651123 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.0131\n",
      "Epoch 30 Batch 100 Loss 0.0069\n",
      "Epoch 30 Batch 200 Loss 0.0139\n",
      "Epoch 30 Batch 300 Loss 0.0141\n",
      "Epoch 30 Batch 400 Loss 0.0113\n",
      "Epoch 30 Batch 500 Loss 0.0121\n",
      "Epoch 30 Batch 600 Loss 0.0097\n",
      "Epoch 30 Batch 700 Loss 0.0148\n",
      "Epoch 30 Loss 0.0109\n",
      "Time taken for 1 epoch 239.51224184036255 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.0050\n",
      "Epoch 31 Batch 100 Loss 0.0117\n",
      "Epoch 31 Batch 200 Loss 0.0100\n",
      "Epoch 31 Batch 300 Loss 0.0116\n",
      "Epoch 31 Batch 400 Loss 0.0086\n",
      "Epoch 31 Batch 500 Loss 0.0122\n",
      "Epoch 31 Batch 600 Loss 0.0118\n",
      "Epoch 31 Batch 700 Loss 0.0084\n",
      "Epoch 31 Loss 0.0103\n",
      "Time taken for 1 epoch 239.01876258850098 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.0049\n",
      "Epoch 32 Batch 100 Loss 0.0043\n",
      "Epoch 32 Batch 200 Loss 0.0157\n",
      "Epoch 32 Batch 300 Loss 0.0066\n",
      "Epoch 32 Batch 400 Loss 0.0128\n",
      "Epoch 32 Batch 500 Loss 0.0085\n",
      "Epoch 32 Batch 600 Loss 0.0170\n",
      "Epoch 32 Batch 700 Loss 0.0111\n",
      "Epoch 32 Loss 0.0104\n",
      "Time taken for 1 epoch 238.0729320049286 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.0140\n",
      "Epoch 33 Batch 100 Loss 0.0053\n",
      "Epoch 33 Batch 200 Loss 0.0081\n",
      "Epoch 33 Batch 300 Loss 0.0105\n",
      "Epoch 33 Batch 400 Loss 0.0123\n",
      "Epoch 33 Batch 500 Loss 0.0146\n",
      "Epoch 33 Batch 600 Loss 0.0140\n",
      "Epoch 33 Batch 700 Loss 0.0184\n",
      "Epoch 33 Loss 0.0135\n",
      "Time taken for 1 epoch 239.5742108821869 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.0158\n",
      "Epoch 34 Batch 100 Loss 0.0121\n",
      "Epoch 34 Batch 200 Loss 0.0077\n",
      "Epoch 34 Batch 300 Loss 0.0184\n",
      "Epoch 34 Batch 400 Loss 0.0073\n",
      "Epoch 34 Batch 500 Loss 0.0114\n",
      "Epoch 34 Batch 600 Loss 0.0166\n",
      "Epoch 34 Batch 700 Loss 0.0139\n",
      "Epoch 34 Loss 0.0119\n",
      "Time taken for 1 epoch 240.78887367248535 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.0071\n",
      "Epoch 35 Batch 100 Loss 0.0102\n",
      "Epoch 35 Batch 200 Loss 0.0135\n",
      "Epoch 35 Batch 300 Loss 0.0121\n",
      "Epoch 35 Batch 400 Loss 0.0090\n",
      "Epoch 35 Batch 500 Loss 0.0108\n",
      "Epoch 35 Batch 600 Loss 0.0112\n",
      "Epoch 35 Batch 700 Loss 0.0081\n",
      "Epoch 35 Loss 0.0105\n",
      "Time taken for 1 epoch 239.78724551200867 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.0028\n",
      "Epoch 36 Batch 100 Loss 0.0083\n",
      "Epoch 36 Batch 200 Loss 0.0043\n",
      "Epoch 36 Batch 300 Loss 0.0056\n",
      "Epoch 36 Batch 400 Loss 0.0051\n",
      "Epoch 36 Batch 500 Loss 0.0095\n",
      "Epoch 36 Batch 600 Loss 0.0078\n",
      "Epoch 36 Batch 700 Loss 0.0109\n",
      "Epoch 36 Loss 0.0084\n",
      "Time taken for 1 epoch 239.47454690933228 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.0061\n",
      "Epoch 37 Batch 100 Loss 0.0100\n",
      "Epoch 37 Batch 200 Loss 0.0036\n",
      "Epoch 37 Batch 300 Loss 0.0124\n",
      "Epoch 37 Batch 400 Loss 0.0124\n",
      "Epoch 37 Batch 500 Loss 0.0134\n",
      "Epoch 37 Batch 600 Loss 0.0101\n",
      "Epoch 37 Batch 700 Loss 0.0143\n",
      "Epoch 37 Loss 0.0101\n",
      "Time taken for 1 epoch 239.10655522346497 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.0155\n",
      "Epoch 38 Batch 100 Loss 0.0100\n",
      "Epoch 38 Batch 200 Loss 0.0106\n",
      "Epoch 38 Batch 300 Loss 0.0106\n",
      "Epoch 38 Batch 400 Loss 0.0106\n",
      "Epoch 38 Batch 500 Loss 0.0148\n",
      "Epoch 38 Batch 600 Loss 0.0123\n",
      "Epoch 38 Batch 700 Loss 0.0099\n",
      "Epoch 38 Loss 0.0109\n",
      "Time taken for 1 epoch 239.50452280044556 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.0112\n",
      "Epoch 39 Batch 100 Loss 0.0122\n",
      "Epoch 39 Batch 200 Loss 0.0035\n",
      "Epoch 39 Batch 300 Loss 0.0031\n",
      "Epoch 39 Batch 400 Loss 0.0054\n",
      "Epoch 39 Batch 500 Loss 0.0082\n",
      "Epoch 39 Batch 600 Loss 0.0108\n",
      "Epoch 39 Batch 700 Loss 0.0075\n",
      "Epoch 39 Loss 0.0095\n",
      "Time taken for 1 epoch 239.9571442604065 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.0070\n",
      "Epoch 40 Batch 100 Loss 0.0100\n",
      "Epoch 40 Batch 200 Loss 0.0149\n",
      "Epoch 40 Batch 300 Loss 0.0093\n",
      "Epoch 40 Batch 400 Loss 0.0135\n",
      "Epoch 40 Batch 500 Loss 0.0052\n",
      "Epoch 40 Batch 600 Loss 0.0101\n",
      "Epoch 40 Batch 700 Loss 0.0304\n",
      "Epoch 40 Loss 0.0104\n",
      "Time taken for 1 epoch 239.0588300228119 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.0148\n",
      "Epoch 41 Batch 100 Loss 0.0041\n",
      "Epoch 41 Batch 200 Loss 0.0105\n",
      "Epoch 41 Batch 300 Loss 0.0065\n",
      "Epoch 41 Batch 400 Loss 0.0078\n",
      "Epoch 41 Batch 500 Loss 0.0096\n",
      "Epoch 41 Batch 600 Loss 0.0104\n",
      "Epoch 41 Batch 700 Loss 0.0134\n",
      "Epoch 41 Loss 0.0100\n",
      "Time taken for 1 epoch 239.54883694648743 sec\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.0082\n",
      "Epoch 42 Batch 100 Loss 0.0057\n",
      "Epoch 42 Batch 200 Loss 0.0096\n",
      "Epoch 42 Batch 300 Loss 0.0040\n",
      "Epoch 42 Batch 400 Loss 0.0051\n",
      "Epoch 42 Batch 500 Loss 0.0107\n",
      "Epoch 42 Batch 600 Loss 0.0079\n",
      "Epoch 42 Batch 700 Loss 0.0093\n",
      "Epoch 42 Loss 0.0086\n",
      "Time taken for 1 epoch 238.9388928413391 sec\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.0092\n",
      "Epoch 43 Batch 100 Loss 0.0129\n",
      "Epoch 43 Batch 200 Loss 0.0094\n",
      "Epoch 43 Batch 300 Loss 0.0051\n",
      "Epoch 43 Batch 400 Loss 0.0119\n",
      "Epoch 43 Batch 500 Loss 0.0136\n",
      "Epoch 43 Batch 600 Loss 0.0089\n",
      "Epoch 43 Batch 700 Loss 0.0124\n",
      "Epoch 43 Loss 0.0101\n",
      "Time taken for 1 epoch 239.92380714416504 sec\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.0129\n",
      "Epoch 44 Batch 100 Loss 0.0088\n",
      "Epoch 44 Batch 200 Loss 0.0156\n",
      "Epoch 44 Batch 300 Loss 0.0108\n",
      "Epoch 44 Batch 400 Loss 0.0068\n",
      "Epoch 44 Batch 500 Loss 0.0083\n",
      "Epoch 44 Batch 600 Loss 0.0126\n",
      "Epoch 44 Batch 700 Loss 0.0109\n",
      "Epoch 44 Loss 0.0098\n",
      "Time taken for 1 epoch 238.92885828018188 sec\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.0169\n",
      "Epoch 45 Batch 100 Loss 0.0037\n",
      "Epoch 45 Batch 200 Loss 0.0121\n",
      "Epoch 45 Batch 300 Loss 0.0085\n",
      "Epoch 45 Batch 400 Loss 0.0152\n",
      "Epoch 45 Batch 500 Loss 0.0120\n",
      "Epoch 45 Batch 600 Loss 0.0133\n",
      "Epoch 45 Batch 700 Loss 0.0180\n",
      "Epoch 45 Loss 0.0097\n",
      "Time taken for 1 epoch 239.96971464157104 sec\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.0191\n",
      "Epoch 46 Batch 100 Loss 0.0145\n",
      "Epoch 46 Batch 200 Loss 0.0119\n",
      "Epoch 46 Batch 300 Loss 0.0120\n",
      "Epoch 46 Batch 400 Loss 0.0199\n",
      "Epoch 46 Batch 500 Loss 0.0144\n",
      "Epoch 46 Batch 600 Loss 0.0129\n",
      "Epoch 46 Batch 700 Loss 0.0176\n",
      "Epoch 46 Loss 0.0121\n",
      "Time taken for 1 epoch 239.46551299095154 sec\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.0036\n",
      "Epoch 47 Batch 100 Loss 0.0111\n",
      "Epoch 47 Batch 200 Loss 0.0047\n",
      "Epoch 47 Batch 300 Loss 0.0099\n",
      "Epoch 47 Batch 400 Loss 0.0122\n",
      "Epoch 47 Batch 500 Loss 0.0133\n",
      "Epoch 47 Batch 600 Loss 0.0071\n",
      "Epoch 47 Batch 700 Loss 0.0101\n",
      "Epoch 47 Loss 0.0098\n",
      "Time taken for 1 epoch 239.37396121025085 sec\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.0105\n",
      "Epoch 48 Batch 100 Loss 0.0027\n",
      "Epoch 48 Batch 200 Loss 0.0060\n",
      "Epoch 48 Batch 300 Loss 0.0029\n",
      "Epoch 48 Batch 400 Loss 0.0199\n",
      "Epoch 48 Batch 500 Loss 0.0113\n",
      "Epoch 48 Batch 600 Loss 0.0077\n",
      "Epoch 48 Batch 700 Loss 0.0073\n",
      "Epoch 48 Loss 0.0078\n",
      "Time taken for 1 epoch 239.16206336021423 sec\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.0043\n",
      "Epoch 49 Batch 100 Loss 0.0050\n",
      "Epoch 49 Batch 200 Loss 0.0061\n",
      "Epoch 49 Batch 300 Loss 0.0121\n",
      "Epoch 49 Batch 400 Loss 0.0188\n",
      "Epoch 49 Batch 500 Loss 0.0029\n",
      "Epoch 49 Batch 600 Loss 0.0120\n",
      "Epoch 49 Batch 700 Loss 0.0066\n",
      "Epoch 49 Loss 0.0081\n",
      "Time taken for 1 epoch 240.3257896900177 sec\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.0078\n",
      "Epoch 50 Batch 100 Loss 0.0066\n",
      "Epoch 50 Batch 200 Loss 0.0167\n",
      "Epoch 50 Batch 300 Loss 0.0077\n",
      "Epoch 50 Batch 400 Loss 0.0127\n",
      "Epoch 50 Batch 500 Loss 0.0089\n",
      "Epoch 50 Batch 600 Loss 0.0100\n",
      "Epoch 50 Batch 700 Loss 0.0110\n",
      "Epoch 50 Loss 0.0098\n",
      "Time taken for 1 epoch 239.13410568237305 sec\n",
      "\n",
      "Epoch 51 Batch 0 Loss 0.0142\n",
      "Epoch 51 Batch 100 Loss 0.0107\n",
      "Epoch 51 Batch 200 Loss 0.0047\n",
      "Epoch 51 Batch 300 Loss 0.0063\n",
      "Epoch 51 Batch 400 Loss 0.0047\n",
      "Epoch 51 Batch 500 Loss 0.0068\n",
      "Epoch 51 Batch 600 Loss 0.0079\n",
      "Epoch 51 Batch 700 Loss 0.0074\n",
      "Epoch 51 Loss 0.0092\n",
      "Time taken for 1 epoch 239.1639323234558 sec\n",
      "\n",
      "Epoch 52 Batch 0 Loss 0.0076\n",
      "Epoch 52 Batch 100 Loss 0.0080\n",
      "Epoch 52 Batch 200 Loss 0.0070\n",
      "Epoch 52 Batch 300 Loss 0.0062\n",
      "Epoch 52 Batch 400 Loss 0.0172\n",
      "Epoch 52 Batch 500 Loss 0.0070\n",
      "Epoch 52 Batch 600 Loss 0.0089\n",
      "Epoch 52 Batch 700 Loss 0.0155\n",
      "Epoch 52 Loss 0.0087\n",
      "Time taken for 1 epoch 238.53884100914001 sec\n",
      "\n",
      "Epoch 53 Batch 0 Loss 0.0083\n",
      "Epoch 53 Batch 100 Loss 0.0033\n",
      "Epoch 53 Batch 200 Loss 0.0062\n",
      "Epoch 53 Batch 300 Loss 0.0064\n",
      "Epoch 53 Batch 400 Loss 0.0069\n",
      "Epoch 53 Batch 500 Loss 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 600 Loss 0.0159\n",
      "Epoch 53 Batch 700 Loss 0.0080\n",
      "Epoch 53 Loss 0.0078\n",
      "Time taken for 1 epoch 239.40477657318115 sec\n",
      "\n",
      "Epoch 54 Batch 0 Loss 0.0073\n",
      "Epoch 54 Batch 100 Loss 0.0065\n",
      "Epoch 54 Batch 200 Loss 0.0068\n",
      "Epoch 54 Batch 300 Loss 0.0065\n",
      "Epoch 54 Batch 400 Loss 0.0118\n",
      "Epoch 54 Batch 500 Loss 0.0035\n",
      "Epoch 54 Batch 600 Loss 0.0117\n",
      "Epoch 54 Batch 700 Loss 0.0127\n",
      "Epoch 54 Loss 0.0083\n",
      "Time taken for 1 epoch 240.37216997146606 sec\n",
      "\n",
      "Epoch 55 Batch 0 Loss 0.0080\n",
      "Epoch 55 Batch 100 Loss 0.0054\n",
      "Epoch 55 Batch 200 Loss 0.0100\n",
      "Epoch 55 Batch 300 Loss 0.0116\n",
      "Epoch 55 Batch 400 Loss 0.0102\n",
      "Epoch 55 Batch 500 Loss 0.0048\n",
      "Epoch 55 Batch 600 Loss 0.0088\n",
      "Epoch 55 Batch 700 Loss 0.0068\n",
      "Epoch 55 Loss 0.0088\n",
      "Time taken for 1 epoch 239.10556173324585 sec\n",
      "\n",
      "Epoch 56 Batch 0 Loss 0.0045\n",
      "Epoch 56 Batch 100 Loss 0.0047\n",
      "Epoch 56 Batch 200 Loss 0.0036\n",
      "Epoch 56 Batch 300 Loss 0.0086\n",
      "Epoch 56 Batch 400 Loss 0.0048\n",
      "Epoch 56 Batch 500 Loss 0.0118\n",
      "Epoch 56 Batch 600 Loss 0.0160\n",
      "Epoch 56 Batch 700 Loss 0.0125\n",
      "Epoch 56 Loss 0.0080\n",
      "Time taken for 1 epoch 239.27453088760376 sec\n",
      "\n",
      "Epoch 57 Batch 0 Loss 0.0059\n",
      "Epoch 57 Batch 100 Loss 0.0133\n",
      "Epoch 57 Batch 200 Loss 0.0064\n",
      "Epoch 57 Batch 300 Loss 0.0062\n",
      "Epoch 57 Batch 400 Loss 0.0099\n",
      "Epoch 57 Batch 500 Loss 0.0113\n",
      "Epoch 57 Batch 600 Loss 0.0076\n",
      "Epoch 57 Batch 700 Loss 0.0073\n",
      "Epoch 57 Loss 0.0096\n",
      "Time taken for 1 epoch 238.40983033180237 sec\n",
      "\n",
      "Epoch 58 Batch 0 Loss 0.0091\n",
      "Epoch 58 Batch 100 Loss 0.0095\n",
      "Epoch 58 Batch 200 Loss 0.0070\n",
      "Epoch 58 Batch 300 Loss 0.0149\n",
      "Epoch 58 Batch 400 Loss 0.0139\n",
      "Epoch 58 Batch 500 Loss 0.0126\n",
      "Epoch 58 Batch 600 Loss 0.0104\n",
      "Epoch 58 Batch 700 Loss 0.0166\n",
      "Epoch 58 Loss 0.0119\n",
      "Time taken for 1 epoch 239.9820396900177 sec\n",
      "\n",
      "Epoch 59 Batch 0 Loss 0.0255\n",
      "Epoch 59 Batch 100 Loss 0.0107\n",
      "Epoch 59 Batch 200 Loss 0.0093\n",
      "Epoch 59 Batch 300 Loss 0.0053\n",
      "Epoch 59 Batch 400 Loss 0.0066\n",
      "Epoch 59 Batch 500 Loss 0.0073\n",
      "Epoch 59 Batch 600 Loss 0.0079\n",
      "Epoch 59 Batch 700 Loss 0.0052\n",
      "Epoch 59 Loss 0.0080\n",
      "Time taken for 1 epoch 239.38334727287292 sec\n",
      "\n",
      "Epoch 60 Batch 0 Loss 0.0124\n",
      "Epoch 60 Batch 100 Loss 0.0071\n",
      "Epoch 60 Batch 200 Loss 0.0048\n",
      "Epoch 60 Batch 300 Loss 0.0054\n",
      "Epoch 60 Batch 400 Loss 0.0057\n",
      "Epoch 60 Batch 500 Loss 0.0055\n",
      "Epoch 60 Batch 600 Loss 0.0042\n",
      "Epoch 60 Batch 700 Loss 0.0098\n",
      "Epoch 60 Loss 0.0069\n",
      "Time taken for 1 epoch 238.61798334121704 sec\n",
      "\n",
      "Epoch 61 Batch 0 Loss 0.0052\n",
      "Epoch 61 Batch 100 Loss 0.0096\n",
      "Epoch 61 Batch 200 Loss 0.0118\n",
      "Epoch 61 Batch 300 Loss 0.0038\n",
      "Epoch 61 Batch 400 Loss 0.0076\n",
      "Epoch 61 Batch 500 Loss 0.0055\n",
      "Epoch 61 Batch 600 Loss 0.0145\n",
      "Epoch 61 Batch 700 Loss 0.0075\n",
      "Epoch 61 Loss 0.0069\n",
      "Time taken for 1 epoch 239.0056767463684 sec\n",
      "\n",
      "Epoch 62 Batch 0 Loss 0.0067\n",
      "Epoch 62 Batch 100 Loss 0.0034\n",
      "Epoch 62 Batch 200 Loss 0.0089\n",
      "Epoch 62 Batch 300 Loss 0.0059\n",
      "Epoch 62 Batch 400 Loss 0.0094\n",
      "Epoch 62 Batch 500 Loss 0.0081\n",
      "Epoch 62 Batch 600 Loss 0.0037\n",
      "Epoch 62 Batch 700 Loss 0.0124\n",
      "Epoch 62 Loss 0.0079\n",
      "Time taken for 1 epoch 240.00999307632446 sec\n",
      "\n",
      "Epoch 63 Batch 0 Loss 0.0039\n",
      "Epoch 63 Batch 100 Loss 0.0012\n",
      "Epoch 63 Batch 200 Loss 0.0039\n",
      "Epoch 63 Batch 300 Loss 0.0156\n",
      "Epoch 63 Batch 400 Loss 0.0128\n",
      "Epoch 63 Batch 500 Loss 0.0048\n",
      "Epoch 63 Batch 600 Loss 0.0091\n",
      "Epoch 63 Batch 700 Loss 0.0108\n",
      "Epoch 63 Loss 0.0076\n",
      "Time taken for 1 epoch 241.17106008529663 sec\n",
      "\n",
      "Epoch 64 Batch 0 Loss 0.0024\n",
      "Epoch 64 Batch 100 Loss 0.0053\n",
      "Epoch 64 Batch 200 Loss 0.0077\n",
      "Epoch 64 Batch 300 Loss 0.0045\n",
      "Epoch 64 Batch 400 Loss 0.0134\n",
      "Epoch 64 Batch 500 Loss 0.0132\n",
      "Epoch 64 Batch 600 Loss 0.0056\n",
      "Epoch 64 Batch 700 Loss 0.0106\n",
      "Epoch 64 Loss 0.0076\n",
      "Time taken for 1 epoch 238.6957552433014 sec\n",
      "\n",
      "Epoch 65 Batch 0 Loss 0.0067\n",
      "Epoch 65 Batch 100 Loss 0.0071\n",
      "Epoch 65 Batch 200 Loss 0.0041\n",
      "Epoch 65 Batch 300 Loss 0.0061\n",
      "Epoch 65 Batch 400 Loss 0.0053\n",
      "Epoch 65 Batch 500 Loss 0.0152\n",
      "Epoch 65 Batch 600 Loss 0.0077\n",
      "Epoch 65 Batch 700 Loss 0.0080\n",
      "Epoch 65 Loss 0.0086\n",
      "Time taken for 1 epoch 239.16932773590088 sec\n",
      "\n",
      "Epoch 66 Batch 0 Loss 0.0052\n",
      "Epoch 66 Batch 100 Loss 0.0040\n",
      "Epoch 66 Batch 200 Loss 0.0054\n",
      "Epoch 66 Batch 300 Loss 0.0084\n",
      "Epoch 66 Batch 400 Loss 0.0066\n",
      "Epoch 66 Batch 500 Loss 0.0059\n",
      "Epoch 66 Batch 600 Loss 0.0085\n",
      "Epoch 66 Batch 700 Loss 0.0083\n",
      "Epoch 66 Loss 0.0087\n",
      "Time taken for 1 epoch 238.40095329284668 sec\n",
      "\n",
      "Epoch 67 Batch 0 Loss 0.0072\n",
      "Epoch 67 Batch 100 Loss 0.0074\n",
      "Epoch 67 Batch 200 Loss 0.0109\n",
      "Epoch 67 Batch 300 Loss 0.0115\n",
      "Epoch 67 Batch 400 Loss 0.0088\n",
      "Epoch 67 Batch 500 Loss 0.0140\n",
      "Epoch 67 Batch 600 Loss 0.0080\n",
      "Epoch 67 Batch 700 Loss 0.0059\n",
      "Epoch 67 Loss 0.0086\n",
      "Time taken for 1 epoch 239.2605049610138 sec\n",
      "\n",
      "Epoch 68 Batch 0 Loss 0.0021\n",
      "Epoch 68 Batch 100 Loss 0.0025\n",
      "Epoch 68 Batch 200 Loss 0.0056\n",
      "Epoch 68 Batch 300 Loss 0.0171\n",
      "Epoch 68 Batch 400 Loss 0.0174\n",
      "Epoch 68 Batch 500 Loss 0.0169\n",
      "Epoch 68 Batch 600 Loss 0.0124\n",
      "Epoch 68 Batch 700 Loss 0.0120\n",
      "Epoch 68 Loss 0.0127\n",
      "Time taken for 1 epoch 239.22890162467957 sec\n",
      "\n",
      "Epoch 69 Batch 0 Loss 0.0090\n",
      "Epoch 69 Batch 100 Loss 0.0042\n",
      "Epoch 69 Batch 200 Loss 0.0065\n",
      "Epoch 69 Batch 300 Loss 0.0089\n",
      "Epoch 69 Batch 400 Loss 0.0143\n",
      "Epoch 69 Batch 500 Loss 0.0108\n",
      "Epoch 69 Batch 600 Loss 0.0079\n",
      "Epoch 69 Batch 700 Loss 0.0104\n",
      "Epoch 69 Loss 0.0087\n",
      "Time taken for 1 epoch 237.29629492759705 sec\n",
      "\n",
      "Epoch 70 Batch 0 Loss 0.0059\n",
      "Epoch 70 Batch 100 Loss 0.0050\n",
      "Epoch 70 Batch 200 Loss 0.0025\n",
      "Epoch 70 Batch 300 Loss 0.0062\n",
      "Epoch 70 Batch 400 Loss 0.0101\n",
      "Epoch 70 Batch 500 Loss 0.0035\n",
      "Epoch 70 Batch 600 Loss 0.0106\n",
      "Epoch 70 Batch 700 Loss 0.0066\n",
      "Epoch 70 Loss 0.0065\n",
      "Time taken for 1 epoch 239.07970023155212 sec\n",
      "\n",
      "Epoch 71 Batch 0 Loss 0.0070\n",
      "Epoch 71 Batch 100 Loss 0.0013\n",
      "Epoch 71 Batch 200 Loss 0.0056\n",
      "Epoch 71 Batch 300 Loss 0.0033\n",
      "Epoch 71 Batch 400 Loss 0.0054\n",
      "Epoch 71 Batch 500 Loss 0.0080\n",
      "Epoch 71 Batch 600 Loss 0.0030\n",
      "Epoch 71 Batch 700 Loss 0.0092\n",
      "Epoch 71 Loss 0.0061\n",
      "Time taken for 1 epoch 239.83563089370728 sec\n",
      "\n",
      "Epoch 72 Batch 0 Loss 0.0036\n",
      "Epoch 72 Batch 100 Loss 0.0042\n",
      "Epoch 72 Batch 200 Loss 0.0049\n",
      "Epoch 72 Batch 300 Loss 0.0104\n",
      "Epoch 72 Batch 400 Loss 0.0130\n",
      "Epoch 72 Batch 500 Loss 0.0043\n",
      "Epoch 72 Batch 600 Loss 0.0100\n",
      "Epoch 72 Batch 700 Loss 0.0046\n",
      "Epoch 72 Loss 0.0061\n",
      "Time taken for 1 epoch 238.8272683620453 sec\n",
      "\n",
      "Epoch 73 Batch 0 Loss 0.0079\n",
      "Epoch 73 Batch 100 Loss 0.0057\n",
      "Epoch 73 Batch 200 Loss 0.0064\n",
      "Epoch 73 Batch 300 Loss 0.0055\n",
      "Epoch 73 Batch 400 Loss 0.0156\n",
      "Epoch 73 Batch 500 Loss 0.0156\n",
      "Epoch 73 Batch 600 Loss 0.0188\n",
      "Epoch 73 Batch 700 Loss 0.0093\n",
      "Epoch 73 Loss 0.0108\n",
      "Time taken for 1 epoch 238.71574354171753 sec\n",
      "\n",
      "Epoch 74 Batch 0 Loss 0.0100\n",
      "Epoch 74 Batch 100 Loss 0.0102\n",
      "Epoch 74 Batch 200 Loss 0.0181\n",
      "Epoch 74 Batch 300 Loss 0.0077\n",
      "Epoch 74 Batch 400 Loss 0.0042\n",
      "Epoch 74 Batch 500 Loss 0.0091\n",
      "Epoch 74 Batch 600 Loss 0.0148\n",
      "Epoch 74 Batch 700 Loss 0.0124\n",
      "Epoch 74 Loss 0.0110\n",
      "Time taken for 1 epoch 240.5988039970398 sec\n",
      "\n",
      "Epoch 75 Batch 0 Loss 0.0081\n",
      "Epoch 75 Batch 100 Loss 0.0053\n",
      "Epoch 75 Batch 200 Loss 0.0062\n",
      "Epoch 75 Batch 300 Loss 0.0042\n",
      "Epoch 75 Batch 400 Loss 0.0121\n",
      "Epoch 75 Batch 500 Loss 0.0061\n",
      "Epoch 75 Batch 600 Loss 0.0123\n",
      "Epoch 75 Batch 700 Loss 0.0114\n",
      "Epoch 75 Loss 0.0082\n",
      "Time taken for 1 epoch 239.3515613079071 sec\n",
      "\n",
      "Epoch 76 Batch 0 Loss 0.0023\n",
      "Epoch 76 Batch 100 Loss 0.0107\n",
      "Epoch 76 Batch 200 Loss 0.0015\n",
      "Epoch 76 Batch 300 Loss 0.0035\n",
      "Epoch 76 Batch 400 Loss 0.0057\n",
      "Epoch 76 Batch 500 Loss 0.0034\n",
      "Epoch 76 Batch 600 Loss 0.0114\n",
      "Epoch 76 Batch 700 Loss 0.0073\n",
      "Epoch 76 Loss 0.0068\n",
      "Time taken for 1 epoch 239.2740762233734 sec\n",
      "\n",
      "Epoch 77 Batch 0 Loss 0.0028\n",
      "Epoch 77 Batch 100 Loss 0.0029\n",
      "Epoch 77 Batch 200 Loss 0.0070\n",
      "Epoch 77 Batch 300 Loss 0.0087\n",
      "Epoch 77 Batch 400 Loss 0.0116\n",
      "Epoch 77 Batch 500 Loss 0.0071\n",
      "Epoch 77 Batch 600 Loss 0.0061\n",
      "Epoch 77 Batch 700 Loss 0.0079\n",
      "Epoch 77 Loss 0.0073\n",
      "Time taken for 1 epoch 239.21386575698853 sec\n",
      "\n",
      "Epoch 78 Batch 0 Loss 0.0080\n",
      "Epoch 78 Batch 100 Loss 0.0045\n",
      "Epoch 78 Batch 200 Loss 0.0067\n",
      "Epoch 78 Batch 300 Loss 0.0111\n",
      "Epoch 78 Batch 400 Loss 0.0073\n",
      "Epoch 78 Batch 500 Loss 0.0122\n",
      "Epoch 78 Batch 600 Loss 0.0100\n",
      "Epoch 78 Batch 700 Loss 0.0065\n",
      "Epoch 78 Loss 0.0080\n",
      "Time taken for 1 epoch 240.33704829216003 sec\n",
      "\n",
      "Epoch 79 Batch 0 Loss 0.0041\n",
      "Epoch 79 Batch 100 Loss 0.0057\n",
      "Epoch 79 Batch 200 Loss 0.0103\n",
      "Epoch 79 Batch 300 Loss 0.0083\n",
      "Epoch 79 Batch 400 Loss 0.0090\n",
      "Epoch 79 Batch 500 Loss 0.0038\n",
      "Epoch 79 Batch 600 Loss 0.0051\n",
      "Epoch 79 Batch 700 Loss 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Loss 0.0081\n",
      "Time taken for 1 epoch 240.33280634880066 sec\n",
      "\n",
      "Epoch 80 Batch 0 Loss 0.0076\n",
      "Epoch 80 Batch 100 Loss 0.0094\n",
      "Epoch 80 Batch 200 Loss 0.0050\n",
      "Epoch 80 Batch 300 Loss 0.0134\n",
      "Epoch 80 Batch 400 Loss 0.0065\n",
      "Epoch 80 Batch 500 Loss 0.0105\n",
      "Epoch 80 Batch 600 Loss 0.0294\n",
      "Epoch 80 Batch 700 Loss 0.0095\n",
      "Epoch 80 Loss 0.0091\n",
      "Time taken for 1 epoch 239.34475994110107 sec\n",
      "\n",
      "Epoch 81 Batch 0 Loss 0.0113\n",
      "Epoch 81 Batch 100 Loss 0.0053\n",
      "Epoch 81 Batch 200 Loss 0.0044\n",
      "Epoch 81 Batch 300 Loss 0.0131\n",
      "Epoch 81 Batch 400 Loss 0.0083\n",
      "Epoch 81 Batch 500 Loss 0.0111\n",
      "Epoch 81 Batch 600 Loss 0.0103\n",
      "Epoch 81 Batch 700 Loss 0.0088\n",
      "Epoch 81 Loss 0.0093\n",
      "Time taken for 1 epoch 239.39016819000244 sec\n",
      "\n",
      "Epoch 82 Batch 0 Loss 0.0078\n",
      "Epoch 82 Batch 100 Loss 0.0070\n",
      "Epoch 82 Batch 200 Loss 0.0068\n",
      "Epoch 82 Batch 300 Loss 0.0092\n",
      "Epoch 82 Batch 400 Loss 0.0050\n",
      "Epoch 82 Batch 500 Loss 0.0209\n",
      "Epoch 82 Batch 600 Loss 0.0048\n",
      "Epoch 82 Batch 700 Loss 0.0070\n",
      "Epoch 82 Loss 0.0075\n",
      "Time taken for 1 epoch 239.62959623336792 sec\n",
      "\n",
      "Epoch 83 Batch 0 Loss 0.0087\n",
      "Epoch 83 Batch 100 Loss 0.0085\n",
      "Epoch 83 Batch 200 Loss 0.0236\n",
      "Epoch 83 Batch 300 Loss 0.0080\n",
      "Epoch 83 Batch 400 Loss 0.0057\n",
      "Epoch 83 Batch 500 Loss 0.0118\n",
      "Epoch 83 Batch 600 Loss 0.0121\n",
      "Epoch 83 Batch 700 Loss 0.0099\n",
      "Epoch 83 Loss 0.0082\n",
      "Time taken for 1 epoch 239.65428566932678 sec\n",
      "\n",
      "Epoch 84 Batch 0 Loss 0.0047\n",
      "Epoch 84 Batch 100 Loss 0.0042\n",
      "Epoch 84 Batch 200 Loss 0.0071\n",
      "Epoch 84 Batch 300 Loss 0.0081\n",
      "Epoch 84 Batch 400 Loss 0.0047\n",
      "Epoch 84 Batch 500 Loss 0.0038\n",
      "Epoch 84 Batch 600 Loss 0.0048\n",
      "Epoch 84 Batch 700 Loss 0.0076\n",
      "Epoch 84 Loss 0.0076\n",
      "Time taken for 1 epoch 240.92062902450562 sec\n",
      "\n",
      "Epoch 85 Batch 0 Loss 0.0016\n",
      "Epoch 85 Batch 100 Loss 0.0040\n",
      "Epoch 85 Batch 200 Loss 0.0035\n",
      "Epoch 85 Batch 300 Loss 0.0044\n",
      "Epoch 85 Batch 400 Loss 0.0065\n",
      "Epoch 85 Batch 500 Loss 0.0054\n",
      "Epoch 85 Batch 600 Loss 0.0112\n",
      "Epoch 85 Batch 700 Loss 0.0053\n",
      "Epoch 85 Loss 0.0071\n",
      "Time taken for 1 epoch 239.3424654006958 sec\n",
      "\n",
      "Epoch 86 Batch 0 Loss 0.0025\n",
      "Epoch 86 Batch 100 Loss 0.0024\n",
      "Epoch 86 Batch 200 Loss 0.0100\n",
      "Epoch 86 Batch 300 Loss 0.0081\n",
      "Epoch 86 Batch 400 Loss 0.0071\n",
      "Epoch 86 Batch 500 Loss 0.0051\n",
      "Epoch 86 Batch 600 Loss 0.0098\n",
      "Epoch 86 Batch 700 Loss 0.0075\n",
      "Epoch 86 Loss 0.0069\n",
      "Time taken for 1 epoch 237.57472014427185 sec\n",
      "\n",
      "Epoch 87 Batch 0 Loss 0.0067\n",
      "Epoch 87 Batch 100 Loss 0.0037\n",
      "Epoch 87 Batch 200 Loss 0.0150\n",
      "Epoch 87 Batch 300 Loss 0.0062\n",
      "Epoch 87 Batch 400 Loss 0.0034\n",
      "Epoch 87 Batch 500 Loss 0.0077\n",
      "Epoch 87 Batch 600 Loss 0.0091\n",
      "Epoch 87 Batch 700 Loss 0.0058\n",
      "Epoch 87 Loss 0.0075\n",
      "Time taken for 1 epoch 239.58983063697815 sec\n",
      "\n",
      "Epoch 88 Batch 0 Loss 0.0053\n",
      "Epoch 88 Batch 100 Loss 0.0043\n",
      "Epoch 88 Batch 200 Loss 0.0147\n",
      "Epoch 88 Batch 300 Loss 0.0154\n",
      "Epoch 88 Batch 400 Loss 0.0082\n",
      "Epoch 88 Batch 500 Loss 0.0041\n",
      "Epoch 88 Batch 600 Loss 0.0151\n",
      "Epoch 88 Batch 700 Loss 0.0083\n",
      "Epoch 88 Loss 0.0092\n",
      "Time taken for 1 epoch 239.52954769134521 sec\n",
      "\n",
      "Epoch 89 Batch 0 Loss 0.0046\n",
      "Epoch 89 Batch 100 Loss 0.0098\n",
      "Epoch 89 Batch 200 Loss 0.0115\n",
      "Epoch 89 Batch 300 Loss 0.0093\n",
      "Epoch 89 Batch 400 Loss 0.0070\n",
      "Epoch 89 Batch 500 Loss 0.0124\n",
      "Epoch 89 Batch 600 Loss 0.0102\n",
      "Epoch 89 Batch 700 Loss 0.0045\n",
      "Epoch 89 Loss 0.0088\n",
      "Time taken for 1 epoch 237.6514618396759 sec\n",
      "\n",
      "Epoch 90 Batch 0 Loss 0.0088\n",
      "Epoch 90 Batch 100 Loss 0.0060\n",
      "Epoch 90 Batch 200 Loss 0.0070\n",
      "Epoch 90 Batch 300 Loss 0.0052\n",
      "Epoch 90 Batch 400 Loss 0.0066\n",
      "Epoch 90 Batch 500 Loss 0.0142\n",
      "Epoch 90 Batch 600 Loss 0.0048\n",
      "Epoch 90 Batch 700 Loss 0.0073\n",
      "Epoch 90 Loss 0.0076\n",
      "Time taken for 1 epoch 238.83676099777222 sec\n",
      "\n",
      "Epoch 91 Batch 0 Loss 0.0103\n",
      "Epoch 91 Batch 100 Loss 0.0113\n",
      "Epoch 91 Batch 200 Loss 0.0047\n",
      "Epoch 91 Batch 300 Loss 0.0031\n",
      "Epoch 91 Batch 400 Loss 0.0083\n",
      "Epoch 91 Batch 500 Loss 0.0052\n",
      "Epoch 91 Batch 600 Loss 0.0137\n",
      "Epoch 91 Batch 700 Loss 0.0045\n",
      "Epoch 91 Loss 0.0069\n",
      "Time taken for 1 epoch 239.7456784248352 sec\n",
      "\n",
      "Epoch 92 Batch 0 Loss 0.0054\n",
      "Epoch 92 Batch 100 Loss 0.0073\n",
      "Epoch 92 Batch 200 Loss 0.0032\n",
      "Epoch 92 Batch 300 Loss 0.0089\n",
      "Epoch 92 Batch 400 Loss 0.0034\n",
      "Epoch 92 Batch 500 Loss 0.0062\n",
      "Epoch 92 Batch 600 Loss 0.0050\n",
      "Epoch 92 Batch 700 Loss 0.0077\n",
      "Epoch 92 Loss 0.0067\n",
      "Time taken for 1 epoch 240.63286757469177 sec\n",
      "\n",
      "Epoch 93 Batch 0 Loss 0.0034\n",
      "Epoch 93 Batch 100 Loss 0.0018\n",
      "Epoch 93 Batch 200 Loss 0.0061\n",
      "Epoch 93 Batch 300 Loss 0.0148\n",
      "Epoch 93 Batch 400 Loss 0.0030\n",
      "Epoch 93 Batch 500 Loss 0.0118\n",
      "Epoch 93 Batch 600 Loss 0.0133\n",
      "Epoch 93 Batch 700 Loss 0.0104\n",
      "Epoch 93 Loss 0.0081\n",
      "Time taken for 1 epoch 239.6912226676941 sec\n",
      "\n",
      "Epoch 94 Batch 0 Loss 0.0033\n",
      "Epoch 94 Batch 100 Loss 0.0068\n",
      "Epoch 94 Batch 200 Loss 0.0039\n",
      "Epoch 94 Batch 300 Loss 0.0086\n",
      "Epoch 94 Batch 400 Loss 0.0124\n",
      "Epoch 94 Batch 500 Loss 0.0079\n",
      "Epoch 94 Batch 600 Loss 0.0110\n",
      "Epoch 94 Batch 700 Loss 0.0050\n",
      "Epoch 94 Loss 0.0088\n",
      "Time taken for 1 epoch 239.4144835472107 sec\n",
      "\n",
      "Epoch 95 Batch 0 Loss 0.0102\n",
      "Epoch 95 Batch 100 Loss 0.0054\n",
      "Epoch 95 Batch 200 Loss 0.0070\n",
      "Epoch 95 Batch 300 Loss 0.0045\n",
      "Epoch 95 Batch 400 Loss 0.0073\n",
      "Epoch 95 Batch 500 Loss 0.0058\n",
      "Epoch 95 Batch 600 Loss 0.0142\n",
      "Epoch 95 Batch 700 Loss 0.0071\n",
      "Epoch 95 Loss 0.0075\n",
      "Time taken for 1 epoch 239.4828906059265 sec\n",
      "\n",
      "Epoch 96 Batch 0 Loss 0.0030\n",
      "Epoch 96 Batch 100 Loss 0.0087\n",
      "Epoch 96 Batch 200 Loss 0.0058\n",
      "Epoch 96 Batch 300 Loss 0.0042\n",
      "Epoch 96 Batch 400 Loss 0.0104\n",
      "Epoch 96 Batch 500 Loss 0.0062\n",
      "Epoch 96 Batch 600 Loss 0.0054\n",
      "Epoch 96 Batch 700 Loss 0.0134\n",
      "Epoch 96 Loss 0.0086\n",
      "Time taken for 1 epoch 240.19584703445435 sec\n",
      "\n",
      "Epoch 97 Batch 0 Loss 0.0127\n",
      "Epoch 97 Batch 100 Loss 0.0069\n",
      "Epoch 97 Batch 200 Loss 0.0069\n",
      "Epoch 97 Batch 300 Loss 0.0032\n",
      "Epoch 97 Batch 400 Loss 0.0079\n",
      "Epoch 97 Batch 500 Loss 0.0068\n",
      "Epoch 97 Batch 600 Loss 0.0087\n",
      "Epoch 97 Batch 700 Loss 0.0052\n",
      "Epoch 97 Loss 0.0094\n",
      "Time taken for 1 epoch 240.64133095741272 sec\n",
      "\n",
      "Epoch 98 Batch 0 Loss 0.0037\n",
      "Epoch 98 Batch 100 Loss 0.0100\n",
      "Epoch 98 Batch 200 Loss 0.0047\n",
      "Epoch 98 Batch 300 Loss 0.0055\n",
      "Epoch 98 Batch 400 Loss 0.0056\n",
      "Epoch 98 Batch 500 Loss 0.0075\n",
      "Epoch 98 Batch 600 Loss 0.0047\n",
      "Epoch 98 Batch 700 Loss 0.0075\n",
      "Epoch 98 Loss 0.0068\n",
      "Time taken for 1 epoch 239.5885455608368 sec\n",
      "\n",
      "Epoch 99 Batch 0 Loss 0.0058\n",
      "Epoch 99 Batch 100 Loss 0.0039\n",
      "Epoch 99 Batch 200 Loss 0.0024\n",
      "Epoch 99 Batch 300 Loss 0.0072\n",
      "Epoch 99 Batch 400 Loss 0.0117\n",
      "Epoch 99 Batch 500 Loss 0.0016\n",
      "Epoch 99 Batch 600 Loss 0.0041\n",
      "Epoch 99 Batch 700 Loss 0.0110\n",
      "Epoch 99 Loss 0.0067\n",
      "Time taken for 1 epoch 239.1825397014618 sec\n",
      "\n",
      "Epoch 100 Batch 0 Loss 0.0098\n",
      "Epoch 100 Batch 100 Loss 0.0071\n",
      "Epoch 100 Batch 200 Loss 0.0069\n",
      "Epoch 100 Batch 300 Loss 0.0061\n",
      "Epoch 100 Batch 400 Loss 0.0056\n",
      "Epoch 100 Batch 500 Loss 0.0158\n",
      "Epoch 100 Batch 600 Loss 0.0083\n",
      "Epoch 100 Batch 700 Loss 0.0060\n",
      "Epoch 100 Loss 0.0083\n",
      "Time taken for 1 epoch 239.7278356552124 sec\n",
      "\n",
      "Epoch 101 Batch 0 Loss 0.0040\n",
      "Epoch 101 Batch 100 Loss 0.0064\n",
      "Epoch 101 Batch 200 Loss 0.0120\n",
      "Epoch 101 Batch 300 Loss 0.0070\n",
      "Epoch 101 Batch 400 Loss 0.0028\n",
      "Epoch 101 Batch 500 Loss 0.0121\n",
      "Epoch 101 Batch 600 Loss 0.0080\n",
      "Epoch 101 Batch 700 Loss 0.0149\n",
      "Epoch 101 Loss 0.0075\n",
      "Time taken for 1 epoch 239.86300349235535 sec\n",
      "\n",
      "Epoch 102 Batch 0 Loss 0.0027\n",
      "Epoch 102 Batch 100 Loss 0.0103\n",
      "Epoch 102 Batch 200 Loss 0.0106\n",
      "Epoch 102 Batch 300 Loss 0.0078\n",
      "Epoch 102 Batch 400 Loss 0.0045\n",
      "Epoch 102 Batch 500 Loss 0.0043\n",
      "Epoch 102 Batch 600 Loss 0.0184\n",
      "Epoch 102 Batch 700 Loss 0.0076\n",
      "Epoch 102 Loss 0.0090\n",
      "Time taken for 1 epoch 239.27302718162537 sec\n",
      "\n",
      "Epoch 103 Batch 0 Loss 0.0070\n",
      "Epoch 103 Batch 100 Loss 0.0088\n",
      "Epoch 103 Batch 200 Loss 0.0086\n",
      "Epoch 103 Batch 300 Loss 0.0083\n",
      "Epoch 103 Batch 400 Loss 0.0086\n",
      "Epoch 103 Batch 500 Loss 0.0106\n",
      "Epoch 103 Batch 600 Loss 0.0140\n",
      "Epoch 103 Batch 700 Loss 0.0169\n",
      "Epoch 103 Loss 0.0099\n",
      "Time taken for 1 epoch 239.32245135307312 sec\n",
      "\n",
      "Epoch 104 Batch 0 Loss 0.0065\n",
      "Epoch 104 Batch 100 Loss 0.0119\n",
      "Epoch 104 Batch 200 Loss 0.0105\n",
      "Epoch 104 Batch 300 Loss 0.0117\n",
      "Epoch 104 Batch 400 Loss 0.0067\n",
      "Epoch 104 Batch 500 Loss 0.0090\n",
      "Epoch 104 Batch 600 Loss 0.0037\n",
      "Epoch 104 Batch 700 Loss 0.0083\n",
      "Epoch 104 Loss 0.0082\n",
      "Time taken for 1 epoch 240.2609941959381 sec\n",
      "\n",
      "Epoch 105 Batch 0 Loss 0.0016\n",
      "Epoch 105 Batch 100 Loss 0.0036\n",
      "Epoch 105 Batch 200 Loss 0.0047\n",
      "Epoch 105 Batch 300 Loss 0.0047\n",
      "Epoch 105 Batch 400 Loss 0.0058\n",
      "Epoch 105 Batch 500 Loss 0.0155\n",
      "Epoch 105 Batch 600 Loss 0.0060\n",
      "Epoch 105 Batch 700 Loss 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 Loss 0.0063\n",
      "Time taken for 1 epoch 238.4763104915619 sec\n",
      "\n",
      "Epoch 106 Batch 0 Loss 0.0023\n",
      "Epoch 106 Batch 100 Loss 0.0015\n",
      "Epoch 106 Batch 200 Loss 0.0032\n",
      "Epoch 106 Batch 300 Loss 0.0101\n",
      "Epoch 106 Batch 400 Loss 0.0013\n",
      "Epoch 106 Batch 500 Loss 0.0094\n",
      "Epoch 106 Batch 600 Loss 0.0038\n",
      "Epoch 106 Batch 700 Loss 0.0044\n",
      "Epoch 106 Loss 0.0058\n",
      "Time taken for 1 epoch 238.57191348075867 sec\n",
      "\n",
      "Epoch 107 Batch 0 Loss 0.0049\n",
      "Epoch 107 Batch 100 Loss 0.0026\n",
      "Epoch 107 Batch 200 Loss 0.0105\n",
      "Epoch 107 Batch 300 Loss 0.0096\n",
      "Epoch 107 Batch 400 Loss 0.0067\n",
      "Epoch 107 Batch 500 Loss 0.0080\n",
      "Epoch 107 Batch 600 Loss 0.0072\n",
      "Epoch 107 Batch 700 Loss 0.0082\n",
      "Epoch 107 Loss 0.0064\n",
      "Time taken for 1 epoch 239.02971601486206 sec\n",
      "\n",
      "Epoch 108 Batch 0 Loss 0.0057\n",
      "Epoch 108 Batch 100 Loss 0.0120\n",
      "Epoch 108 Batch 200 Loss 0.0084\n",
      "Epoch 108 Batch 300 Loss 0.0050\n",
      "Epoch 108 Batch 400 Loss 0.0092\n",
      "Epoch 108 Batch 500 Loss 0.0084\n",
      "Epoch 108 Batch 600 Loss 0.0065\n",
      "Epoch 108 Batch 700 Loss 0.0071\n",
      "Epoch 108 Loss 0.0091\n",
      "Time taken for 1 epoch 238.60935878753662 sec\n",
      "\n",
      "Epoch 109 Batch 0 Loss 0.0076\n",
      "Epoch 109 Batch 100 Loss 0.0069\n",
      "Epoch 109 Batch 200 Loss 0.0045\n",
      "Epoch 109 Batch 300 Loss 0.0081\n",
      "Epoch 109 Batch 400 Loss 0.0155\n",
      "Epoch 109 Batch 500 Loss 0.0059\n",
      "Epoch 109 Batch 600 Loss 0.0135\n",
      "Epoch 109 Batch 700 Loss 0.0124\n",
      "Epoch 109 Loss 0.0090\n",
      "Time taken for 1 epoch 239.84218764305115 sec\n",
      "\n",
      "Epoch 110 Batch 0 Loss 0.0032\n",
      "Epoch 110 Batch 100 Loss 0.0100\n",
      "Epoch 110 Batch 200 Loss 0.0074\n",
      "Epoch 110 Batch 300 Loss 0.0075\n",
      "Epoch 110 Batch 400 Loss 0.0053\n",
      "Epoch 110 Batch 500 Loss 0.0051\n",
      "Epoch 110 Batch 600 Loss 0.0087\n",
      "Epoch 110 Batch 700 Loss 0.0054\n",
      "Epoch 110 Loss 0.0076\n",
      "Time taken for 1 epoch 240.58797669410706 sec\n",
      "\n",
      "Epoch 111 Batch 0 Loss 0.0055\n",
      "Epoch 111 Batch 100 Loss 0.0039\n",
      "Epoch 111 Batch 200 Loss 0.0050\n",
      "Epoch 111 Batch 300 Loss 0.0067\n",
      "Epoch 111 Batch 400 Loss 0.0057\n",
      "Epoch 111 Batch 500 Loss 0.0037\n",
      "Epoch 111 Batch 600 Loss 0.0063\n",
      "Epoch 111 Batch 700 Loss 0.0060\n",
      "Epoch 111 Loss 0.0075\n",
      "Time taken for 1 epoch 239.67873525619507 sec\n",
      "\n",
      "Epoch 112 Batch 0 Loss 0.0048\n",
      "Epoch 112 Batch 100 Loss 0.0045\n",
      "Epoch 112 Batch 200 Loss 0.0035\n",
      "Epoch 112 Batch 300 Loss 0.0062\n",
      "Epoch 112 Batch 400 Loss 0.0130\n",
      "Epoch 112 Batch 500 Loss 0.0082\n",
      "Epoch 112 Batch 600 Loss 0.0068\n",
      "Epoch 112 Batch 700 Loss 0.0110\n",
      "Epoch 112 Loss 0.0079\n",
      "Time taken for 1 epoch 238.84933304786682 sec\n",
      "\n",
      "Epoch 113 Batch 0 Loss 0.0021\n",
      "Epoch 113 Batch 100 Loss 0.0034\n",
      "Epoch 113 Batch 200 Loss 0.0062\n",
      "Epoch 113 Batch 300 Loss 0.0052\n",
      "Epoch 113 Batch 400 Loss 0.0111\n",
      "Epoch 113 Batch 500 Loss 0.0121\n",
      "Epoch 113 Batch 600 Loss 0.0080\n",
      "Epoch 113 Batch 700 Loss 0.0110\n",
      "Epoch 113 Loss 0.0078\n",
      "Time taken for 1 epoch 237.83163452148438 sec\n",
      "\n",
      "Epoch 114 Batch 0 Loss 0.0054\n",
      "Epoch 114 Batch 100 Loss 0.0058\n",
      "Epoch 114 Batch 200 Loss 0.0032\n",
      "Epoch 114 Batch 300 Loss 0.0101\n",
      "Epoch 114 Batch 400 Loss 0.0138\n",
      "Epoch 114 Batch 500 Loss 0.0035\n",
      "Epoch 114 Batch 600 Loss 0.0105\n",
      "Epoch 114 Batch 700 Loss 0.0119\n",
      "Epoch 114 Loss 0.0074\n",
      "Time taken for 1 epoch 238.713796377182 sec\n",
      "\n",
      "Epoch 115 Batch 0 Loss 0.0043\n",
      "Epoch 115 Batch 100 Loss 0.0067\n",
      "Epoch 115 Batch 200 Loss 0.0198\n",
      "Epoch 115 Batch 300 Loss 0.0088\n",
      "Epoch 115 Batch 400 Loss 0.0088\n",
      "Epoch 115 Batch 500 Loss 0.0054\n",
      "Epoch 115 Batch 600 Loss 0.0087\n",
      "Epoch 115 Batch 700 Loss 0.0147\n",
      "Epoch 115 Loss 0.0108\n",
      "Time taken for 1 epoch 238.32466077804565 sec\n",
      "\n",
      "Epoch 116 Batch 0 Loss 0.0040\n",
      "Epoch 116 Batch 100 Loss 0.0046\n",
      "Epoch 116 Batch 200 Loss 0.0053\n",
      "Epoch 116 Batch 300 Loss 0.0208\n",
      "Epoch 116 Batch 400 Loss 0.0087\n",
      "Epoch 116 Batch 500 Loss 0.0074\n",
      "Epoch 116 Batch 600 Loss 0.0053\n",
      "Epoch 116 Batch 700 Loss 0.0129\n",
      "Epoch 116 Loss 0.0073\n",
      "Time taken for 1 epoch 239.06314420700073 sec\n",
      "\n",
      "Epoch 117 Batch 0 Loss 0.0046\n",
      "Epoch 117 Batch 100 Loss 0.0064\n",
      "Epoch 117 Batch 200 Loss 0.0066\n",
      "Epoch 117 Batch 300 Loss 0.0063\n",
      "Epoch 117 Batch 400 Loss 0.0023\n",
      "Epoch 117 Batch 500 Loss 0.0044\n",
      "Epoch 117 Batch 600 Loss 0.0103\n",
      "Epoch 117 Batch 700 Loss 0.0030\n",
      "Epoch 117 Loss 0.0063\n",
      "Time taken for 1 epoch 239.4818000793457 sec\n",
      "\n",
      "Epoch 118 Batch 0 Loss 0.0099\n",
      "Epoch 118 Batch 100 Loss 0.0055\n",
      "Epoch 118 Batch 200 Loss 0.0076\n",
      "Epoch 118 Batch 300 Loss 0.0061\n",
      "Epoch 118 Batch 400 Loss 0.0067\n",
      "Epoch 118 Batch 500 Loss 0.0084\n",
      "Epoch 118 Batch 600 Loss 0.0131\n",
      "Epoch 118 Batch 700 Loss 0.0136\n",
      "Epoch 118 Loss 0.0080\n",
      "Time taken for 1 epoch 238.54451036453247 sec\n",
      "\n",
      "Epoch 119 Batch 0 Loss 0.0072\n",
      "Epoch 119 Batch 100 Loss 0.0051\n",
      "Epoch 119 Batch 200 Loss 0.0037\n",
      "Epoch 119 Batch 300 Loss 0.0075\n",
      "Epoch 119 Batch 400 Loss 0.0111\n",
      "Epoch 119 Batch 500 Loss 0.0085\n",
      "Epoch 119 Batch 600 Loss 0.0124\n",
      "Epoch 119 Batch 700 Loss 0.0150\n",
      "Epoch 119 Loss 0.0081\n",
      "Time taken for 1 epoch 238.11358308792114 sec\n",
      "\n",
      "Epoch 120 Batch 0 Loss 0.0098\n",
      "Epoch 120 Batch 100 Loss 0.0059\n",
      "Epoch 120 Batch 200 Loss 0.0174\n",
      "Epoch 120 Batch 300 Loss 0.0046\n",
      "Epoch 120 Batch 400 Loss 0.0064\n",
      "Epoch 120 Batch 500 Loss 0.0131\n",
      "Epoch 120 Batch 600 Loss 0.0076\n",
      "Epoch 120 Batch 700 Loss 0.0140\n",
      "Epoch 120 Loss 0.0090\n",
      "Time taken for 1 epoch 238.7201385498047 sec\n",
      "\n",
      "Epoch 121 Batch 0 Loss 0.0083\n",
      "Epoch 121 Batch 100 Loss 0.0121\n",
      "Epoch 121 Batch 200 Loss 0.0030\n",
      "Epoch 121 Batch 300 Loss 0.0098\n",
      "Epoch 121 Batch 400 Loss 0.0066\n",
      "Epoch 121 Batch 500 Loss 0.0048\n",
      "Epoch 121 Batch 600 Loss 0.0079\n",
      "Epoch 121 Batch 700 Loss 0.0133\n",
      "Epoch 121 Loss 0.0066\n",
      "Time taken for 1 epoch 238.27387928962708 sec\n",
      "\n",
      "Epoch 122 Batch 0 Loss 0.0072\n",
      "Epoch 122 Batch 100 Loss 0.0108\n",
      "Epoch 122 Batch 200 Loss 0.0076\n",
      "Epoch 122 Batch 300 Loss 0.0051\n",
      "Epoch 122 Batch 400 Loss 0.0079\n",
      "Epoch 122 Batch 500 Loss 0.0039\n",
      "Epoch 122 Batch 600 Loss 0.0054\n",
      "Epoch 122 Batch 700 Loss 0.0095\n",
      "Epoch 122 Loss 0.0063\n",
      "Time taken for 1 epoch 239.72276735305786 sec\n",
      "\n",
      "Epoch 123 Batch 0 Loss 0.0009\n",
      "Epoch 123 Batch 100 Loss 0.0053\n",
      "Epoch 123 Batch 200 Loss 0.0097\n",
      "Epoch 123 Batch 300 Loss 0.0077\n",
      "Epoch 123 Batch 400 Loss 0.0070\n",
      "Epoch 123 Batch 500 Loss 0.0029\n",
      "Epoch 123 Batch 600 Loss 0.0104\n",
      "Epoch 123 Batch 700 Loss 0.0114\n",
      "Epoch 123 Loss 0.0071\n",
      "Time taken for 1 epoch 238.28156399726868 sec\n",
      "\n",
      "Epoch 124 Batch 0 Loss 0.0094\n",
      "Epoch 124 Batch 100 Loss 0.0051\n",
      "Epoch 124 Batch 200 Loss 0.0053\n",
      "Epoch 124 Batch 300 Loss 0.0067\n",
      "Epoch 124 Batch 400 Loss 0.0065\n",
      "Epoch 124 Batch 500 Loss 0.0125\n",
      "Epoch 124 Batch 600 Loss 0.0026\n",
      "Epoch 124 Batch 700 Loss 0.0125\n",
      "Epoch 124 Loss 0.0085\n",
      "Time taken for 1 epoch 239.7947244644165 sec\n",
      "\n",
      "Epoch 125 Batch 0 Loss 0.0032\n",
      "Epoch 125 Batch 100 Loss 0.0123\n",
      "Epoch 125 Batch 200 Loss 0.0078\n",
      "Epoch 125 Batch 300 Loss 0.0129\n",
      "Epoch 125 Batch 400 Loss 0.0138\n",
      "Epoch 125 Batch 500 Loss 0.0085\n",
      "Epoch 125 Batch 600 Loss 0.0093\n",
      "Epoch 125 Batch 700 Loss 0.0182\n",
      "Epoch 125 Loss 0.0079\n",
      "Time taken for 1 epoch 239.1456367969513 sec\n",
      "\n",
      "Epoch 126 Batch 0 Loss 0.0058\n",
      "Epoch 126 Batch 100 Loss 0.0130\n",
      "Epoch 126 Batch 200 Loss 0.0032\n",
      "Epoch 126 Batch 300 Loss 0.0047\n",
      "Epoch 126 Batch 400 Loss 0.0070\n",
      "Epoch 126 Batch 500 Loss 0.0163\n",
      "Epoch 126 Batch 600 Loss 0.0032\n",
      "Epoch 126 Batch 700 Loss 0.0134\n",
      "Epoch 126 Loss 0.0076\n",
      "Time taken for 1 epoch 238.53056812286377 sec\n",
      "\n",
      "Epoch 127 Batch 0 Loss 0.0102\n",
      "Epoch 127 Batch 100 Loss 0.0054\n",
      "Epoch 127 Batch 200 Loss 0.0085\n",
      "Epoch 127 Batch 300 Loss 0.0051\n",
      "Epoch 127 Batch 400 Loss 0.0068\n",
      "Epoch 127 Batch 500 Loss 0.0083\n",
      "Epoch 127 Batch 600 Loss 0.0108\n",
      "Epoch 127 Batch 700 Loss 0.0087\n",
      "Epoch 127 Loss 0.0081\n",
      "Time taken for 1 epoch 238.57588744163513 sec\n",
      "\n",
      "Epoch 128 Batch 0 Loss 0.0046\n",
      "Epoch 128 Batch 100 Loss 0.0053\n",
      "Epoch 128 Batch 200 Loss 0.0036\n",
      "Epoch 128 Batch 300 Loss 0.0108\n",
      "Epoch 128 Batch 400 Loss 0.0029\n",
      "Epoch 128 Batch 500 Loss 0.0198\n",
      "Epoch 128 Batch 600 Loss 0.0052\n",
      "Epoch 128 Batch 700 Loss 0.0147\n",
      "Epoch 128 Loss 0.0082\n",
      "Time taken for 1 epoch 239.70604515075684 sec\n",
      "\n",
      "Epoch 129 Batch 0 Loss 0.0057\n",
      "Epoch 129 Batch 100 Loss 0.0081\n",
      "Epoch 129 Batch 200 Loss 0.0111\n",
      "Epoch 129 Batch 300 Loss 0.0054\n",
      "Epoch 129 Batch 400 Loss 0.0089\n",
      "Epoch 129 Batch 500 Loss 0.0049\n",
      "Epoch 129 Batch 600 Loss 0.0095\n",
      "Epoch 129 Batch 700 Loss 0.0090\n",
      "Epoch 129 Loss 0.0078\n",
      "Time taken for 1 epoch 237.70047760009766 sec\n",
      "\n",
      "Epoch 130 Batch 0 Loss 0.0082\n",
      "Epoch 130 Batch 100 Loss 0.0065\n",
      "Epoch 130 Batch 200 Loss 0.0146\n",
      "Epoch 130 Batch 300 Loss 0.0045\n",
      "Epoch 130 Batch 400 Loss 0.0077\n",
      "Epoch 130 Batch 500 Loss 0.0046\n",
      "Epoch 130 Batch 600 Loss 0.0107\n",
      "Epoch 130 Batch 700 Loss 0.0089\n",
      "Epoch 130 Loss 0.0071\n",
      "Time taken for 1 epoch 238.17712426185608 sec\n",
      "\n",
      "Epoch 131 Batch 0 Loss 0.0023\n",
      "Epoch 131 Batch 100 Loss 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131 Batch 200 Loss 0.0044\n",
      "Epoch 131 Batch 300 Loss 0.0081\n",
      "Epoch 131 Batch 400 Loss 0.0087\n",
      "Epoch 131 Batch 500 Loss 0.0043\n",
      "Epoch 131 Batch 600 Loss 0.0103\n",
      "Epoch 131 Batch 700 Loss 0.0123\n",
      "Epoch 131 Loss 0.0083\n",
      "Time taken for 1 epoch 239.3335976600647 sec\n",
      "\n",
      "Epoch 132 Batch 0 Loss 0.0092\n",
      "Epoch 132 Batch 100 Loss 0.0037\n",
      "Epoch 132 Batch 200 Loss 0.0130\n",
      "Epoch 132 Batch 300 Loss 0.0121\n",
      "Epoch 132 Batch 400 Loss 0.0196\n",
      "Epoch 132 Batch 500 Loss 0.0085\n",
      "Epoch 132 Batch 600 Loss 0.0031\n",
      "Epoch 132 Batch 700 Loss 0.0119\n",
      "Epoch 132 Loss 0.0093\n",
      "Time taken for 1 epoch 239.4116461277008 sec\n",
      "\n",
      "Epoch 133 Batch 0 Loss 0.0050\n",
      "Epoch 133 Batch 100 Loss 0.0030\n",
      "Epoch 133 Batch 200 Loss 0.0076\n",
      "Epoch 133 Batch 300 Loss 0.0084\n",
      "Epoch 133 Batch 400 Loss 0.0079\n",
      "Epoch 133 Batch 500 Loss 0.0054\n",
      "Epoch 133 Batch 600 Loss 0.0109\n",
      "Epoch 133 Batch 700 Loss 0.0101\n",
      "Epoch 133 Loss 0.0072\n",
      "Time taken for 1 epoch 238.97585487365723 sec\n",
      "\n",
      "Epoch 134 Batch 0 Loss 0.0045\n",
      "Epoch 134 Batch 100 Loss 0.0046\n",
      "Epoch 134 Batch 200 Loss 0.0068\n",
      "Epoch 134 Batch 300 Loss 0.0035\n",
      "Epoch 134 Batch 400 Loss 0.0072\n",
      "Epoch 134 Batch 500 Loss 0.0034\n",
      "Epoch 134 Batch 600 Loss 0.0045\n",
      "Epoch 134 Batch 700 Loss 0.0042\n",
      "Epoch 134 Loss 0.0070\n",
      "Time taken for 1 epoch 239.58207416534424 sec\n",
      "\n",
      "Epoch 135 Batch 0 Loss 0.0098\n",
      "Epoch 135 Batch 100 Loss 0.0071\n",
      "Epoch 135 Batch 200 Loss 0.0080\n",
      "Epoch 135 Batch 300 Loss 0.0165\n",
      "Epoch 135 Batch 400 Loss 0.0070\n",
      "Epoch 135 Batch 500 Loss 0.0112\n",
      "Epoch 135 Batch 600 Loss 0.0156\n",
      "Epoch 135 Batch 700 Loss 0.0111\n",
      "Epoch 135 Loss 0.0093\n",
      "Time taken for 1 epoch 239.49018669128418 sec\n",
      "\n",
      "Epoch 136 Batch 0 Loss 0.0066\n",
      "Epoch 136 Batch 100 Loss 0.0114\n",
      "Epoch 136 Batch 200 Loss 0.0196\n",
      "Epoch 136 Batch 300 Loss 0.0083\n",
      "Epoch 136 Batch 400 Loss 0.0117\n",
      "Epoch 136 Batch 500 Loss 0.0065\n",
      "Epoch 136 Batch 600 Loss 0.0058\n",
      "Epoch 136 Batch 700 Loss 0.0069\n",
      "Epoch 136 Loss 0.0083\n",
      "Time taken for 1 epoch 240.95264315605164 sec\n",
      "\n",
      "Epoch 137 Batch 0 Loss 0.0078\n",
      "Epoch 137 Batch 100 Loss 0.0037\n",
      "Epoch 137 Batch 200 Loss 0.0059\n",
      "Epoch 137 Batch 300 Loss 0.0044\n",
      "Epoch 137 Batch 400 Loss 0.0022\n",
      "Epoch 137 Batch 500 Loss 0.0041\n",
      "Epoch 137 Batch 600 Loss 0.0075\n",
      "Epoch 137 Batch 700 Loss 0.0055\n",
      "Epoch 137 Loss 0.0067\n",
      "Time taken for 1 epoch 238.2427318096161 sec\n",
      "\n",
      "Epoch 138 Batch 0 Loss 0.0032\n",
      "Epoch 138 Batch 100 Loss 0.0050\n",
      "Epoch 138 Batch 200 Loss 0.0027\n",
      "Epoch 138 Batch 300 Loss 0.0067\n",
      "Epoch 138 Batch 400 Loss 0.0083\n",
      "Epoch 138 Batch 500 Loss 0.0103\n",
      "Epoch 138 Batch 600 Loss 0.0037\n",
      "Epoch 138 Batch 700 Loss 0.0050\n",
      "Epoch 138 Loss 0.0063\n",
      "Time taken for 1 epoch 238.94437336921692 sec\n",
      "\n",
      "Epoch 139 Batch 0 Loss 0.0058\n",
      "Epoch 139 Batch 100 Loss 0.0058\n",
      "Epoch 139 Batch 200 Loss 0.0029\n",
      "Epoch 139 Batch 300 Loss 0.0039\n",
      "Epoch 139 Batch 400 Loss 0.0051\n",
      "Epoch 139 Batch 500 Loss 0.0069\n",
      "Epoch 139 Batch 600 Loss 0.0053\n",
      "Epoch 139 Batch 700 Loss 0.0054\n",
      "Epoch 139 Loss 0.0065\n",
      "Time taken for 1 epoch 238.934228181839 sec\n",
      "\n",
      "Epoch 140 Batch 0 Loss 0.0040\n",
      "Epoch 140 Batch 100 Loss 0.0056\n",
      "Epoch 140 Batch 200 Loss 0.0057\n",
      "Epoch 140 Batch 300 Loss 0.0078\n",
      "Epoch 140 Batch 400 Loss 0.0049\n",
      "Epoch 140 Batch 500 Loss 0.0062\n",
      "Epoch 140 Batch 600 Loss 0.0076\n",
      "Epoch 140 Batch 700 Loss 0.0103\n",
      "Epoch 140 Loss 0.0100\n",
      "Time taken for 1 epoch 238.29983925819397 sec\n",
      "\n",
      "Epoch 141 Batch 0 Loss 0.0092\n",
      "Epoch 141 Batch 100 Loss 0.0059\n",
      "Epoch 141 Batch 200 Loss 0.0089\n",
      "Epoch 141 Batch 300 Loss 0.0139\n",
      "Epoch 141 Batch 400 Loss 0.0165\n",
      "Epoch 141 Batch 500 Loss 0.0062\n",
      "Epoch 141 Batch 600 Loss 0.0129\n",
      "Epoch 141 Batch 700 Loss 0.0092\n",
      "Epoch 141 Loss 0.0095\n",
      "Time taken for 1 epoch 238.9104197025299 sec\n",
      "\n",
      "Epoch 142 Batch 0 Loss 0.0040\n",
      "Epoch 142 Batch 100 Loss 0.0095\n",
      "Epoch 142 Batch 200 Loss 0.0104\n",
      "Epoch 142 Batch 300 Loss 0.0038\n",
      "Epoch 142 Batch 400 Loss 0.0050\n",
      "Epoch 142 Batch 500 Loss 0.0079\n",
      "Epoch 142 Batch 600 Loss 0.0037\n",
      "Epoch 142 Batch 700 Loss 0.0036\n",
      "Epoch 142 Loss 0.0069\n",
      "Time taken for 1 epoch 237.87791514396667 sec\n",
      "\n",
      "Epoch 143 Batch 0 Loss 0.0073\n",
      "Epoch 143 Batch 100 Loss 0.0105\n",
      "Epoch 143 Batch 200 Loss 0.0014\n",
      "Epoch 143 Batch 300 Loss 0.0023\n",
      "Epoch 143 Batch 400 Loss 0.0069\n",
      "Epoch 143 Batch 500 Loss 0.0039\n",
      "Epoch 143 Batch 600 Loss 0.0065\n",
      "Epoch 143 Batch 700 Loss 0.0019\n",
      "Epoch 143 Loss 0.0060\n",
      "Time taken for 1 epoch 239.57313466072083 sec\n",
      "\n",
      "Epoch 144 Batch 0 Loss 0.0055\n",
      "Epoch 144 Batch 100 Loss 0.0043\n",
      "Epoch 144 Batch 200 Loss 0.0028\n",
      "Epoch 144 Batch 300 Loss 0.0035\n",
      "Epoch 144 Batch 400 Loss 0.0042\n",
      "Epoch 144 Batch 500 Loss 0.0083\n",
      "Epoch 144 Batch 600 Loss 0.0066\n",
      "Epoch 144 Batch 700 Loss 0.0050\n",
      "Epoch 144 Loss 0.0064\n",
      "Time taken for 1 epoch 238.00500559806824 sec\n",
      "\n",
      "Epoch 145 Batch 0 Loss 0.0049\n",
      "Epoch 145 Batch 100 Loss 0.0065\n",
      "Epoch 145 Batch 200 Loss 0.0058\n",
      "Epoch 145 Batch 300 Loss 0.0037\n",
      "Epoch 145 Batch 400 Loss 0.0066\n",
      "Epoch 145 Batch 500 Loss 0.0119\n",
      "Epoch 145 Batch 600 Loss 0.0104\n",
      "Epoch 145 Batch 700 Loss 0.0068\n",
      "Epoch 145 Loss 0.0077\n",
      "Time taken for 1 epoch 239.0753846168518 sec\n",
      "\n",
      "Epoch 146 Batch 0 Loss 0.0034\n",
      "Epoch 146 Batch 100 Loss 0.0153\n",
      "Epoch 146 Batch 200 Loss 0.0123\n",
      "Epoch 146 Batch 300 Loss 0.0060\n",
      "Epoch 146 Batch 400 Loss 0.0111\n",
      "Epoch 146 Batch 500 Loss 0.0134\n",
      "Epoch 146 Batch 600 Loss 0.0175\n",
      "Epoch 146 Batch 700 Loss 0.0069\n",
      "Epoch 146 Loss 0.0088\n",
      "Time taken for 1 epoch 238.31534028053284 sec\n",
      "\n",
      "Epoch 147 Batch 0 Loss 0.0031\n",
      "Epoch 147 Batch 100 Loss 0.0136\n",
      "Epoch 147 Batch 200 Loss 0.0053\n",
      "Epoch 147 Batch 300 Loss 0.0253\n",
      "Epoch 147 Batch 400 Loss 0.0060\n",
      "Epoch 147 Batch 500 Loss 0.0099\n",
      "Epoch 147 Batch 600 Loss 0.0053\n",
      "Epoch 147 Batch 700 Loss 0.0126\n",
      "Epoch 147 Loss 0.0111\n",
      "Time taken for 1 epoch 240.29370498657227 sec\n",
      "\n",
      "Epoch 148 Batch 0 Loss 0.0168\n",
      "Epoch 148 Batch 100 Loss 0.0032\n",
      "Epoch 148 Batch 200 Loss 0.0066\n",
      "Epoch 148 Batch 300 Loss 0.0058\n",
      "Epoch 148 Batch 400 Loss 0.0105\n",
      "Epoch 148 Batch 500 Loss 0.0104\n",
      "Epoch 148 Batch 600 Loss 0.0171\n",
      "Epoch 148 Batch 700 Loss 0.0069\n",
      "Epoch 148 Loss 0.0085\n",
      "Time taken for 1 epoch 240.44868063926697 sec\n",
      "\n",
      "Epoch 149 Batch 0 Loss 0.0076\n",
      "Epoch 149 Batch 100 Loss 0.0034\n",
      "Epoch 149 Batch 200 Loss 0.0074\n",
      "Epoch 149 Batch 300 Loss 0.0088\n",
      "Epoch 149 Batch 400 Loss 0.0044\n",
      "Epoch 149 Batch 500 Loss 0.0104\n",
      "Epoch 149 Batch 600 Loss 0.0037\n",
      "Epoch 149 Batch 700 Loss 0.0158\n",
      "Epoch 149 Loss 0.0068\n",
      "Time taken for 1 epoch 239.60458874702454 sec\n",
      "\n",
      "Epoch 150 Batch 0 Loss 0.0058\n",
      "Epoch 150 Batch 100 Loss 0.0047\n",
      "Epoch 150 Batch 200 Loss 0.0019\n",
      "Epoch 150 Batch 300 Loss 0.0092\n",
      "Epoch 150 Batch 400 Loss 0.0063\n",
      "Epoch 150 Batch 500 Loss 0.0112\n",
      "Epoch 150 Batch 600 Loss 0.0070\n",
      "Epoch 150 Batch 700 Loss 0.0089\n",
      "Epoch 150 Loss 0.0061\n",
      "Time taken for 1 epoch 239.72973728179932 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 150\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "  # 에포크가 2번 실행될때마다 모델 저장 (체크포인트)\n",
    "  # if (epoch + 1) % 2 == 0:\n",
    "  #   checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translation(Spain -> English)\n",
    "\n",
    "*   tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen='', padding='post') : 일정한 길이(maxlen)로 맞춰준다. (패딩은 뒤에서)\n",
    "*   \n",
    "\n",
    "  ```\n",
    "  inp_lang.word_index :  {'<start>': 1, '<end>': 2, '.': 3, 'tom': 4, '?': 5...}\n",
    "  ```\n",
    "\n",
    "* tf.expand_dims: 차원을 늘려준다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "h-wAUSiGFujZ"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "#   attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "#   sentence = preprocess_sentence(sentence)\n",
    "\n",
    "#   inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "\n",
    "  # 문장, input 딕셔너리 출력 \n",
    "  print ('sentence:', sentence)\n",
    "\n",
    "  no_word = 'no word'\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = []\n",
    "  for i in sentence.split(' '):\n",
    "    \n",
    "    if i in inp_lang.word_index:\n",
    "        inputs.append(inp_lang.word_index[i])\n",
    "    else:\n",
    "        print('no word!')\n",
    "        return no_word, sentence\n",
    "    \n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "    \n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "#       return result, sentence, attention_plot\n",
    "      return result, sentence\n",
    "\n",
    "    # 예측된 ID를 모델에 다시 피드합니다.\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "#   return result, sentence, attention_plot\n",
    "  return result, sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "X1uJo_rwvQxJ"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "#   result, sentence, attention_plot = evaluate(sentence)\n",
    "  result, sentence = evaluate(sentence)\n",
    "  \n",
    "  return result\n",
    "#   print('Input: %s' % (sentence))\n",
    "#   print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypD8jH0QvV6-",
    "outputId": "819f4a6f-2ff5-4f35-a87a-36fee3f6eb81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f51d724b610>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_dir내에 있는 최근 체크포인트(checkpoint)를 복원합니다.\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: El va a la escuela.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'he goes to school . <end> '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(u'El va a la escuela.')   # He is going to school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: El va a la escuela.\n"
     ]
    }
   ],
   "source": [
    "result = translate(u'El va a la escuela.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he goes to school . <end> '"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 'Te dijeron lo que pasó, ¿no?'\n",
      "\n",
      "sentence: 'Ellos no estaban allá.'\n",
      "\n",
      "sentence: 'No me gusta ninguno de los chicos.'\n",
      "\n",
      "sentence: 'Jamás trabajé con él.'\n",
      "\n",
      "sentence: 'Mi padre cultiva arroz.'\n",
      "\n",
      "sentence: 'Dime qué hiciste en Shounan.'\n",
      "\n",
      "sentence: '¿Cuántas palabras deberías escribir?'\n",
      "\n",
      "sentence: '¿Cómo te introdujiste en mi casa?'\n",
      "\n",
      "sentence: 'Mi madre hornea pan todas las mañanas.'\n",
      "\n",
      "sentence: 'Yo he disfrutado el leer esta novela.'\n",
      "\n",
      "sentence: 'Él estaba parado en la esquina.'\n",
      "\n",
      "sentence: 'El testigo no parecía estar nervioso cuando testificó en el juicio.'\n",
      "\n",
      "sentence: '¿Dónde está el zoológico?'\n",
      "\n",
      "sentence: 'El nombre de mi hijo es Tom.'\n",
      "\n",
      "sentence: 'Tenemos cosas más grandes de qué preocuparnos.'\n",
      "\n",
      "sentence: 'Juntémonos pasado mañana.'\n",
      "\n",
      "sentence: '¿Qué estás escribiendo?'\n",
      "\n",
      "sentence: '¿Este es tu vino?'\n",
      "\n",
      "sentence: 'Era casi imposible circular por esa calle.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Pensé que Tom querría ayudarme.'\n",
      "\n",
      "sentence: '¿Qué le quieres regalar a Tom?'\n",
      "\n",
      "sentence: 'No quiero permitir que eso suceda.'\n",
      "\n",
      "sentence: 'No queda rollo de papel.'\n",
      "\n",
      "sentence: '¿Vas a venir a visitarme?'\n",
      "\n",
      "sentence: 'Asumo que estás aquí para preguntarme por Tom.'\n",
      "\n",
      "sentence: 'Tom le apreció a Mary su bondad.'\n",
      "\n",
      "sentence: '¿Dónde está la otra?'\n",
      "\n",
      "sentence: 'Los pobres no siempre son infelices.'\n",
      "\n",
      "sentence: 'La perseverancia, como usted sabe, es la llave al éxito.'\n",
      "\n",
      "sentence: 'Tom aparece a veces en la televisión.'\n",
      "\n",
      "sentence: 'Me gusta el perro.'\n",
      "\n",
      "sentence: 'Es algo que tengo que hacer.'\n",
      "\n",
      "sentence: 'Tom no era muy bueno para leer entre líneas.'\n",
      "\n",
      "sentence: '¿Podrías venir acá?'\n",
      "\n",
      "sentence: 'Esa racha de suerte no durará para siempre.'\n",
      "\n",
      "sentence: '¿Caminaste todo el camino hasta acá?'\n",
      "\n",
      "no word!\n",
      "sentence: 'Pensé que Tom había dejado a Mary hace un mes.'\n",
      "\n",
      "sentence: 'Dibuja una línea en el folio.'\n",
      "\n",
      "no word!\n",
      "sentence: 'La fogata sigue encendida.'\n",
      "\n",
      "sentence: 'Es cruel burlarse de un ciego.'\n",
      "\n",
      "sentence: '¡Qué hermoso regalo!'\n",
      "\n",
      "sentence: 'Actualmente, Tom no tiene empleo.'\n",
      "\n",
      "sentence: 'La ciudad estaba envuelta en niebla.'\n",
      "\n",
      "sentence: '¿Sabes cómo usar esto?'\n",
      "\n",
      "sentence: 'Tom cenó hace más o menos una hora.'\n",
      "\n",
      "sentence: '¿Podrías darme tu nombre y tu número de teléfono?'\n",
      "\n",
      "sentence: 'Los documentos secretos fueron triturados.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom está en una racha de suerte.'\n",
      "\n",
      "sentence: 'El enemigo más terrible es un amigo pasado.'\n",
      "\n",
      "sentence: 'Tom es un conductor muy precavido.'\n",
      "\n",
      "sentence: 'Venderé mi casa.'\n",
      "\n",
      "sentence: 'Tom está un poco resfriado.'\n",
      "\n",
      "sentence: 'Arrodillaos.'\n",
      "\n",
      "no word!\n",
      "sentence: '¡Qué tontería!'\n",
      "\n",
      "sentence: 'Este cuchillo está tan desafilado que no puede cortar.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Será mejor que empieces ya.'\n",
      "\n",
      "sentence: '¿A que Tom es popular?'\n",
      "\n",
      "sentence: 'No sé por qué él renunció a la compañía.'\n",
      "\n",
      "sentence: 'Por favor déjame ir.'\n",
      "\n",
      "sentence: 'La ceremonia inaugural se realizó ayer.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Por eso quiero hablar con Tom.'\n",
      "\n",
      "sentence: 'Sin importar cuánto coma, ella no sube de peso.'\n",
      "\n",
      "sentence: 'Es un milagro que Tom siga vivo.'\n",
      "\n",
      "sentence: 'Conduce con cuidado.'\n",
      "\n",
      "sentence: 'En verano, la gente va a la playa.'\n",
      "\n",
      "sentence: 'Por favor, saque la lengua.'\n",
      "\n",
      "sentence: 'Tom tiene una calva.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Me gustaría que le echaras un vistazo.'\n",
      "\n",
      "sentence: 'Durante la guerra, la gente pasó muchos apuros.'\n",
      "\n",
      "sentence: '¿Con quién desea hablar?'\n",
      "\n",
      "sentence: '¿Son americanos?'\n",
      "\n",
      "sentence: 'Tengo un hijo y una hija. Mi hijo está en Nueva York y mi hija en Londres.'\n",
      "\n",
      "sentence: 'Llevo marcapasos.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Este trabajo es lo suficientemente simple para que lo haga un niño.'\n",
      "\n",
      "sentence: 'Nunca he ido al extranjero.'\n",
      "\n",
      "sentence: 'Comamos mientras esté caliente.'\n",
      "\n",
      "sentence: 'Odio estar soltero.'\n",
      "\n",
      "sentence: 'No os preocupéis por mí.'\n",
      "\n",
      "sentence: 'Ella me evita.'\n",
      "\n",
      "sentence: 'Me desperté tres veces durante la noche.'\n",
      "\n",
      "sentence: 'El niño cogió un pez grande.'\n",
      "\n",
      "sentence: 'Tom perdió sus gafas.'\n",
      "\n",
      "sentence: 'La puerta se abrió y un hombre entró.'\n",
      "\n",
      "sentence: 'Me gusta la pizza fría.'\n",
      "\n",
      "sentence: '¿Puedo llamar a Londres desde aquí?'\n",
      "\n",
      "sentence: 'Dígalo en inglés.'\n",
      "\n",
      "sentence: 'Por esa razón perdió su trabajo.'\n",
      "\n",
      "sentence: 'Creo que eres tonto.'\n",
      "\n",
      "sentence: 'Extraño a mis amigos.'\n",
      "\n",
      "sentence: 'Él me enseñó a usar esta cámara.'\n",
      "\n",
      "sentence: 'Esta casa es demasiado chica para vivir.'\n",
      "\n",
      "sentence: 'Tom me dijo eso antes.'\n",
      "\n",
      "sentence: 'El salmón va río arriba y pone sus huevos en la arena.'\n",
      "\n",
      "sentence: 'Bebe mucha agua.'\n",
      "\n",
      "sentence: '¡No seas ridículo!'\n",
      "\n",
      "sentence: 'Estoy sin blanca.'\n",
      "\n",
      "sentence: 'No nos importa lo que él haga.'\n",
      "\n",
      "sentence: '¿Es hoy viernes?'\n",
      "\n",
      "sentence: 'Dije que podía ir.'\n",
      "\n",
      "sentence: '¿A quién se lo diste?'\n",
      "\n",
      "sentence: 'Nunca se ha hecho antes.'\n",
      "\n",
      "sentence: '¿Cuántos ordenadores habéis tenido hasta ahora?'\n",
      "\n",
      "sentence: 'Tom dijo que estaría aquí pero no lo encuentro.'\n",
      "\n",
      "sentence: 'Me han hecho esperar mucho.'\n",
      "\n",
      "sentence: 'Todavía sueño con eso.'\n",
      "\n",
      "sentence: 'Tom ya está en Boston.'\n",
      "\n",
      "sentence: 'El hombre se prendió a si mismo en llamas.'\n",
      "\n",
      "sentence: 'Estoy un poco loca.'\n",
      "\n",
      "sentence: 'Estoy segura de que lo lograréis.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom no quería trabajar horas extra en Noche Buena.'\n",
      "\n",
      "sentence: 'Él levantó los ojos al cielo.'\n",
      "\n",
      "sentence: 'Puedes usar mi bicicleta.'\n",
      "\n",
      "sentence: 'Tom no puede nadar tan rápido como Mary.'\n",
      "\n",
      "sentence: 'Yo no entiendo el arte moderno.'\n",
      "\n",
      "sentence: 'Sé unas cuantas cosas.'\n",
      "\n",
      "sentence: '¿Alguien puede ayudarme?'\n",
      "\n",
      "sentence: '¿Tienes una familia grande?'\n",
      "\n",
      "sentence: 'Tom empezó a comer.'\n",
      "\n",
      "sentence: 'Son felices.'\n",
      "\n",
      "sentence: 'Hay un mapa en la pared.'\n",
      "\n",
      "sentence: 'Tom no mantuvo su promesa.'\n",
      "\n",
      "sentence: 'Nuestra memoria empeora mientras más viejos nos hacemos.'\n",
      "\n",
      "sentence: 'Él tenía tres hijos.'\n",
      "\n",
      "sentence: '¿Has pintado esta casa alguna vez?'\n",
      "\n",
      "sentence: '¿Ya comiste?'\n",
      "\n",
      "sentence: 'Todo eso es culpa vuestra.'\n",
      "\n",
      "sentence: '¿Lo pillas?'\n",
      "\n",
      "sentence: 'Dijeron que los costos de almacenamiento eran demasiado altos.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Algo terrible pasó.'\n",
      "\n",
      "sentence: 'Me gustas como amigo.'\n",
      "\n",
      "sentence: 'Voy a España la semana que viene.'\n",
      "\n",
      "sentence: 'Mi cantante favorita es Kylie Minogue.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No puedo beber alcohol.'\n",
      "\n",
      "sentence: 'Pensé que teníamos un trato.'\n",
      "\n",
      "sentence: '¡Dámelas!'\n",
      "\n",
      "no word!\n",
      "sentence: 'Que no se te olvide escribirnos.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No puede refrenar sus deseos.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Yo corrí una milla.'\n",
      "\n",
      "sentence: 'Eres un fraude.'\n",
      "\n",
      "sentence: 'No creo que Tom y Mary sean hermanos.'\n",
      "\n",
      "sentence: '¿Conoces a un buen dentista?'\n",
      "\n",
      "sentence: 'Hice un trato con Tom.'\n",
      "\n",
      "sentence: 'Tiene el nombre de Tom en el.'\n",
      "\n",
      "sentence: 'Yo no tengo ganas de hablar.'\n",
      "\n",
      "sentence: 'Estoy cansado de todo este fastidio.'\n",
      "\n",
      "sentence: 'Tus manos están frías.'\n",
      "\n",
      "sentence: 'Prosigamos.'\n",
      "\n",
      "sentence: 'No fueron capaces de descubrir ningún secreto.'\n",
      "\n",
      "sentence: 'Tomás es muy mañoso.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No es de buena educación hablar con la boca llena.'\n",
      "\n",
      "sentence: 'Yo me siento adormitado.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Creo que mirar televisión es una pérdida de tiempo.'\n",
      "\n",
      "sentence: 'La reina Elizabeth I falleció en 1603.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Él ha escrito muchas historias.'\n",
      "\n",
      "sentence: 'De todos los libros publicados últimamente, solo algunos merecen ser leídos.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Necesito regresar.'\n",
      "\n",
      "sentence: 'Probate este pullover.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom actúa como si ni conociera a María.'\n",
      "\n",
      "sentence: 'Es mi última oferta.'\n",
      "\n",
      "sentence: 'No me voy a casar nunca.'\n",
      "\n",
      "sentence: 'No necesitas ir tan apurado.'\n",
      "\n",
      "sentence: '¡Para de decir eso!'\n",
      "\n",
      "sentence: 'Los pilotos se comunican con el aeropuerto por radio.'\n",
      "\n",
      "sentence: 'La chica de la que te hablé vive en Kioto.'\n",
      "\n",
      "sentence: 'Lo que necesitamos ahora es un descanso.'\n",
      "\n",
      "sentence: 'Sé breve.'\n",
      "\n",
      "sentence: 'No conozco a ninguna de las dos hermanas.'\n",
      "\n",
      "sentence: 'Nadie me escuchó.'\n",
      "\n",
      "sentence: 'Esos son nuestros autos.'\n",
      "\n",
      "sentence: 'Ella prometió revisar inmediatamente el asunto.'\n",
      "\n",
      "sentence: '¿Había alguien más en el bar?'\n",
      "\n",
      "sentence: 'Ayer fui a ver el partido de béisbol.'\n",
      "\n",
      "sentence: 'Sé tan poco como tú.'\n",
      "\n",
      "sentence: 'Mi papá está en el baño afeitándose.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Han pasado dos semanas y no la he visto.'\n",
      "\n",
      "sentence: 'Guardé lo mejor para el final.'\n",
      "\n",
      "sentence: 'Pusimos los regalos de Navidad bajo el árbol.'\n",
      "\n",
      "sentence: 'No profundices demasiado en esta lectura.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom no ha freído el pescado aún.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Dígame la verdad.'\n",
      "\n",
      "sentence: 'Tómese esta medicina antes de cada comida.'\n",
      "\n",
      "sentence: 'Mi hermano menor nada todos los días en verano.'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: '¿Por qué ella es tan popular?'\n",
      "\n",
      "sentence: 'Dame un pedazo de papel para escribir, por favor.'\n",
      "\n",
      "sentence: 'Para Hawking, escribir este libro no fue fácil.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No sabía que supieras conducir.'\n",
      "\n",
      "sentence: 'Casi todas las chicas son amables.'\n",
      "\n",
      "sentence: 'Llevaré dos completos con mostaza y ketchup.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No creo que Tom vaya a regresar.'\n",
      "\n",
      "sentence: 'Tom, ¿qué quieres de cenar?'\n",
      "\n",
      "sentence: 'Alrededor del año 174 a.C., su gente se volvió contra Roma.'\n",
      "\n",
      "sentence: 'Kenia solía ser una colonia inglesa.'\n",
      "\n",
      "sentence: '¿Qué tal estuvo la fiesta de Tom?'\n",
      "\n",
      "sentence: 'Tom dijo que entiende cómo te sientes.'\n",
      "\n",
      "sentence: 'Viven en la Tercera Avenida.'\n",
      "\n",
      "sentence: 'Me sorprendió lo mucho que se parecía a su padre.'\n",
      "\n",
      "sentence: 'Tom tendrá que esperar.'\n",
      "\n",
      "sentence: 'Tom fue incapaz de disimular su sorpresa.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Necesito a alguien con quien hablar.'\n",
      "\n",
      "sentence: 'Estaba pensando en otra cosa.'\n",
      "\n",
      "sentence: 'Tom finalmente se calmó.'\n",
      "\n",
      "sentence: 'Necesitas que hablemos de tú a tú.'\n",
      "\n",
      "sentence: 'Este es un buen sushi.'\n",
      "\n",
      "sentence: 'No tengo prisa.'\n",
      "\n",
      "sentence: 'Según la leyenda esta casa está embrujada.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Todo está en tu cabeza.'\n",
      "\n",
      "sentence: 'Esperaré hasta las cuatro en punto.'\n",
      "\n",
      "sentence: '¿Por qué está tan caliente?'\n",
      "\n",
      "sentence: '¿Cuándo pasó?'\n",
      "\n",
      "sentence: 'Es difícil creer lo que dices.'\n",
      "\n",
      "sentence: 'Necesitas esto.'\n",
      "\n",
      "sentence: 'Has bebido tres tazas de café.'\n",
      "\n",
      "sentence: '¿Somos amigas?'\n",
      "\n",
      "sentence: 'Iré aunque llueva.'\n",
      "\n",
      "sentence: 'Tom está jugando con sus juguetes.'\n",
      "\n",
      "sentence: 'Los celos en una relación a menudo son provocados por la falta de confianza.'\n",
      "\n",
      "no word!\n",
      "sentence: '¿Hace tanto frío en Alemania como en Canadá?'\n",
      "\n",
      "sentence: 'Su consejo no nos sirvió de nada.'\n",
      "\n",
      "sentence: 'Por favor toma tu tiempo.'\n",
      "\n",
      "sentence: 'Él es muy viejo.'\n",
      "\n",
      "sentence: 'Puede que sea posible para él, pero yo nunca pasaré la prueba.'\n",
      "\n",
      "sentence: 'Tom quería comprar un par nuevo de zapatillas de tenis.'\n",
      "\n",
      "sentence: 'Se le rompió la cuerda al reloj.'\n",
      "\n",
      "sentence: 'Dejarás de hacer eso si sabes lo que es bueno para ti.'\n",
      "\n",
      "sentence: '¡Lo lamentarás!'\n",
      "\n",
      "sentence: 'Hay una necesidad urgente de dinero.'\n",
      "\n",
      "sentence: 'Tienen que ser estadounidenses.'\n",
      "\n",
      "sentence: 'No tuvimos muchas visitas este verano.'\n",
      "\n",
      "sentence: 'Todos los camaradas dormían.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom tiene miedo al compromiso.'\n",
      "\n",
      "sentence: 'Eso no es de tu incumbencia.'\n",
      "\n",
      "sentence: 'Queremos ir de Boston a Chicago.'\n",
      "\n",
      "sentence: 'Ella se decidió por el abrigo rojo.'\n",
      "\n",
      "sentence: 'Creía que eras mayor.'\n",
      "\n",
      "sentence: '¿Qué ha ocurrido?'\n",
      "\n",
      "sentence: 'Muéstrame cómo tengo que hacerlo, por favor.'\n",
      "\n",
      "sentence: '¿Ahora puedo empezar a comer?'\n",
      "\n",
      "sentence: 'No tengo palabras.'\n",
      "\n",
      "sentence: 'Vamos a intentarlo.'\n",
      "\n",
      "sentence: '¿Y de ahí, qué hubo?'\n",
      "\n",
      "sentence: 'Hace frío hoy.'\n",
      "\n",
      "sentence: 'Tengo una idea diferente.'\n",
      "\n",
      "sentence: '¿Puedo ofrecerle algo de beber?'\n",
      "\n",
      "sentence: 'La pequeña isla llegó a la vista.'\n",
      "\n",
      "sentence: 'El chico abrazó a su pecho al cachorro.'\n",
      "\n",
      "sentence: 'No sabía que estarían aquí.'\n",
      "\n",
      "sentence: 'Tom es un buen cliente.'\n",
      "\n",
      "sentence: '¿Estás enojada?'\n",
      "\n",
      "sentence: 'Indícame adónde ir.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No es tan fácil como la gente piensa.'\n",
      "\n",
      "sentence: 'No sé cómo comprar un billete.'\n",
      "\n",
      "sentence: 'Mi hobby es coleccionar estampillas.'\n",
      "\n",
      "sentence: '¿Cuál es el siguiente paso que hay que dar?'\n",
      "\n",
      "sentence: 'La frase siguiente es falsa.'\n",
      "\n",
      "sentence: 'Esperaré otros cinco minutos.'\n",
      "\n",
      "sentence: 'Yo pienso que es demasiado arriesgado.'\n",
      "\n",
      "sentence: 'Nunca cuestionaría su honestidad.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Los pasajeros se pusieron nerviosos cuando el avión comenzó a vibrar.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tengo que averiguar la verdad'\n",
      "\n",
      "sentence: 'Ya he encontrado lo que estaba buscando.'\n",
      "\n",
      "sentence: 'Ahora le quiere más que antes.'\n",
      "\n",
      "sentence: 'Esto es un harpa.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tal vez deberíamos esperar.'\n",
      "\n",
      "sentence: 'Quiero una gominola.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom se está probando zapatos.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Voy a estudiar mucho.'\n",
      "\n",
      "sentence: 'Él está seguro de su éxito.'\n",
      "\n",
      "sentence: 'Tom volvió adentro.'\n",
      "\n",
      "sentence: 'Él murió tras una larga enfermedad.'\n",
      "\n",
      "sentence: 'Contacte a mi hijo.'\n",
      "\n",
      "sentence: 'Sé lo raro que es esto.'\n",
      "\n",
      "sentence: 'Soplaba un viento fuerte.'\n",
      "\n",
      "sentence: 'Está rota.'\n",
      "\n",
      "sentence: 'No queremos presionarte.'\n",
      "\n",
      "no word!\n",
      "sentence: '¿Hay lugar para otra persona?'\n",
      "\n",
      "sentence: 'Quiero ayudarte con los deberes.'\n",
      "\n",
      "sentence: 'No nos gustan nuestros vecinos, y a ellos tampoco les gustamos nosotros.'\n",
      "\n",
      "sentence: 'Para de hacer el vago y encuentra algo que hacer.'\n",
      "\n",
      "sentence: 'Los pensamientos se expresan con palabras.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom llamó a Mary para decirle que podría necesitar su ayuda después esa tarde.'\n",
      "\n",
      "sentence: 'Un extranjero me preguntó en dónde queda la estación.'\n",
      "\n",
      "sentence: 'Las polillas son atraídas por la luz.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Deberíamos dejar descansar a los perros dormidos.'\n",
      "\n",
      "sentence: 'No sé si queremos hacerlo.'\n",
      "\n",
      "sentence: 'Creo que fue un malentendido.'\n",
      "\n",
      "sentence: 'Es tu deber terminar el trabajo.'\n",
      "\n",
      "sentence: '¿Me podrían dar un trozo de tarta de queso?'\n",
      "\n",
      "sentence: 'Dile a Tom que no estaré allí.'\n",
      "\n",
      "sentence: 'No hables con la boca llena.'\n",
      "\n",
      "sentence: 'Me costó conseguir una entrada para el concierto.'\n",
      "\n",
      "sentence: 'Nos vemos una vez por mes.'\n",
      "\n",
      "sentence: 'Es uno de los libros más conocidos de la literatura brasilera.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom y Mary han estado divorciados por más de tres años. \"¿En serio? No lo sabía.\"'\n",
      "\n",
      "sentence: 'Tenemos que encontrar una nueva niñera.'\n",
      "\n",
      "sentence: 'Tenemos que prevenir a Tom.'\n",
      "\n",
      "sentence: 'Sé que todos ustedes son unos cobardes.'\n",
      "\n",
      "sentence: '¿Puedes arrojar alguna luz en esto?'\n",
      "\n",
      "sentence: '¿Sabes cómo cocinar bien el arroz?'\n",
      "\n",
      "sentence: 'No queremos causar ningún problema.'\n",
      "\n",
      "sentence: 'Le puse algo de leche a mi café.'\n",
      "\n",
      "sentence: 'Este texto está destinado a los principiantes.'\n",
      "\n",
      "sentence: '¿Quién te contó la historia?'\n",
      "\n",
      "sentence: 'Le vemos todos los días.'\n",
      "\n",
      "sentence: 'Ellos no cederán.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom estaba muy complacido con los resultados.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Si no come, morirá.'\n",
      "\n",
      "sentence: 'Ayudémonos los unos a los otros.'\n",
      "\n",
      "no word!\n",
      "sentence: '¿Cómo sabes qué tan difícil es?'\n",
      "\n",
      "sentence: 'Ella lo derrotó.'\n",
      "\n",
      "sentence: 'Ya conoces a la gente.'\n",
      "\n",
      "sentence: 'Tom, ¿estás ahí?'\n",
      "\n",
      "sentence: 'Tenemos un cocinero excelente.'\n",
      "\n",
      "sentence: 'Me comí el queso.'\n",
      "\n",
      "sentence: 'Esta teoría es para mí demasiado difícil de entender.'\n",
      "\n",
      "sentence: 'Siempre me saqué buenas notas en francés.'\n",
      "\n",
      "sentence: 'No pudimos parar de reír.'\n",
      "\n",
      "sentence: 'Tom fue a Boston a visitar a su tío.'\n",
      "\n",
      "sentence: 'Ayer vi televisión por dos horas.'\n",
      "\n",
      "sentence: 'Ese viejo es muy chiqueado para la comida.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Habla claramente.'\n",
      "\n",
      "sentence: 'Tengo que elegir entre esos dos.'\n",
      "\n",
      "sentence: '¿Qué es lo que haces?'\n",
      "\n",
      "sentence: 'Él sacó los huevos uno por uno.'\n",
      "\n",
      "sentence: 'Su carcajada hizo eco por toda la casa.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Nunca me dijiste que tenías una hermana.'\n",
      "\n",
      "sentence: 'Él hizo lo que le dijeron.'\n",
      "\n",
      "sentence: 'Tom le susurró algo a Mary.'\n",
      "\n",
      "sentence: 'Me gusta particularmente el olor de las lilas.'\n",
      "\n",
      "no word!\n",
      "sentence: '¿Me prestas tu auto esta noche?'\n",
      "\n",
      "sentence: 'El gasto llegó a doce pesos.'\n",
      "\n",
      "sentence: 'No seas tan descuidado en tu trabajo.'\n",
      "\n",
      "sentence: 'Ven aquí y únetenos.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No puedo esperar para salir de vacaciones.'\n",
      "\n",
      "sentence: 'Nuestro partido de fútbol será pospuesto.'\n",
      "\n",
      "sentence: 'La tormenta destruyó toda la ciudad.'\n",
      "\n",
      "sentence: 'Iba a usarlo.'\n",
      "\n",
      "sentence: 'Esperame.'\n",
      "\n",
      "sentence: '¿Qué lleva este guiso?'\n",
      "\n",
      "sentence: '¿Dónde está la pasta de dientes?'\n",
      "\n",
      "sentence: 'La chica que lleva un vestido blanco es mi hermana.'\n",
      "\n",
      "sentence: 'No olvides verme mañana por la mañana.'\n",
      "\n",
      "sentence: 'No soy esclavo de Tomás.'\n",
      "\n",
      "sentence: 'Estaré afuera.'\n",
      "\n",
      "sentence: 'Nos perdimos en el bosque.'\n",
      "\n",
      "sentence: 'No tengo suficiente dinero para comprarlo.'\n",
      "\n",
      "sentence: 'El cuarto mes se llama abril.'\n",
      "\n",
      "sentence: 'Ella lo llama todas las noches y habla al menos una hora.'\n",
      "\n",
      "sentence: 'Adondequiera que vayas, conocerás gente amable y generosa.'\n",
      "\n",
      "sentence: '¡Dejad sitio!'\n",
      "\n",
      "sentence: '¿Por qué me llamaste?'\n",
      "\n",
      "sentence: 'La mancha de tinta no se sale.'\n",
      "\n",
      "sentence: 'No pienses que no lo intenté.'\n",
      "\n",
      "sentence: 'Tom tendrá éxito.'\n",
      "\n",
      "sentence: 'A Tom se le hizo tarde.'\n",
      "\n",
      "sentence: 'Adoro el deporte.'\n",
      "\n",
      "sentence: 'La meta es estar fuera del país dentro de una hora.'\n",
      "\n",
      "sentence: 'Se acabó.'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 'Quiero que se vaya.'\n",
      "\n",
      "sentence: 'No te muevas.'\n",
      "\n",
      "sentence: '¿Por qué no estaban allí?'\n",
      "\n",
      "sentence: 'No respondió al teléfono, así que le mandé un correo.'\n",
      "\n",
      "sentence: 'Yo no te di un regalo.'\n",
      "\n",
      "sentence: '¿Cómo suena eso?'\n",
      "\n",
      "sentence: 'Esta noche vamos al cine.'\n",
      "\n",
      "sentence: 'Vimos una momia en el museo.'\n",
      "\n",
      "no word!\n",
      "sentence: '¿En qué momento estudias?'\n",
      "\n",
      "sentence: 'Ellos me miraban en silencio.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Este es un gran proyecto.'\n",
      "\n",
      "sentence: 'Él sabe hablar japonés.'\n",
      "\n",
      "sentence: 'Existe un grado de estrés en todos los trabajos.'\n",
      "\n",
      "sentence: 'Una catástrofe ha sido impedida.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No sabía que hacer entonces.'\n",
      "\n",
      "sentence: 'Me pregunto dónde se estará escondiendo.'\n",
      "\n",
      "sentence: 'Estoy demasiado borracho.'\n",
      "\n",
      "sentence: '¿Le falta a usted algo en su cartera?'\n",
      "\n",
      "sentence: '¿Te gustaría un plátano?'\n",
      "\n",
      "sentence: 'Repetí mi nombre.'\n",
      "\n",
      "sentence: 'Ella quisiera que él se pusiera en contacto con ella tan pronto como sea posible.'\n",
      "\n",
      "sentence: 'A todos le agradabas.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Se dijo a sí mismo, \"lo haré\".'\n",
      "\n",
      "sentence: 'Desenchufa la televisión y apaga la luz.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Compré dos camisas de algodón.'\n",
      "\n",
      "sentence: 'Mi padre va a ser operado.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Busqué el libro por una hora.'\n",
      "\n",
      "sentence: 'He recibido una buena oferta de trabajo.'\n",
      "\n",
      "sentence: 'Papá normalmente viene a casa a las ocho.'\n",
      "\n",
      "sentence: 'Espera por mí aquí.'\n",
      "\n",
      "sentence: 'El año pasado pasé tanto tiempo solo que casi se me olvidó cómo comunicarme de una manera eficaz con los otros.'\n",
      "\n",
      "sentence: '¡Mejor que cerrés el pico!'\n",
      "\n",
      "no word!\n",
      "sentence: 'Sé que puede ser duro.'\n",
      "\n",
      "sentence: '¿Por qué no puedes explicar qué estás haciendo?'\n",
      "\n",
      "sentence: 'Hoy día estoy realmente cansado.'\n",
      "\n",
      "sentence: 'Ese muchacho no mostró ningún temor.'\n",
      "\n",
      "sentence: 'Su padre le dejó la casa en su testamento.'\n",
      "\n",
      "sentence: 'Tom estaba feliz al respecto.'\n",
      "\n",
      "sentence: '¿Qué tiene que ver eso conmigo?'\n",
      "\n",
      "sentence: 'Estos libros facilitarán su trabajo.'\n",
      "\n",
      "no word!\n",
      "sentence: '¿Ya has leído este libro?'\n",
      "\n",
      "sentence: 'Las matemáticas son mi asignatura favorita.'\n",
      "\n",
      "sentence: '¿Estás pensando seriamente en comerte todo eso?'\n",
      "\n",
      "sentence: 'No había otra opción excepto sentarse y esperar.'\n",
      "\n",
      "sentence: 'Tom le susurró algo al oído a María y ella asintió.'\n",
      "\n",
      "sentence: 'Pareces ocupado.'\n",
      "\n",
      "sentence: 'Él sostenía una caja grande en los brazos.'\n",
      "\n",
      "sentence: 'La población de Shangai es tan grande como la de Tokio.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Ha pasado una semana, pero todavía estoy sufriendo el jet lag.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Yo crecí en esa casa.'\n",
      "\n",
      "sentence: '¿Comer yema de huevo es realmente poco saludable?'\n",
      "\n",
      "sentence: 'Me parece que habéis ido demasiado lejos.'\n",
      "\n",
      "sentence: 'Llegué a la estación a las seis.'\n",
      "\n",
      "sentence: 'Perdió a su padre cuando tenía tres años.'\n",
      "\n",
      "sentence: 'Le gusto.'\n",
      "\n",
      "sentence: 'No podés escapar.'\n",
      "\n",
      "sentence: 'Ellos originalmente eran granjeros.'\n",
      "\n",
      "sentence: 'A pesar de las dificultades de idioma, todos nos hicimos amigos rápido.'\n",
      "\n",
      "sentence: 'Me gustaría comprar una heladera.'\n",
      "\n",
      "sentence: 'Quiero cantar la canción.'\n",
      "\n",
      "sentence: 'Tom trató de matarse.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom parece muy incómodo.'\n",
      "\n",
      "sentence: 'Mi celular está sonando.'\n",
      "\n",
      "sentence: 'Esta melodía les resultará familiar a muchos japoneses.'\n",
      "\n",
      "sentence: 'Ella va a una escuela para sordos.'\n",
      "\n",
      "sentence: 'Él sabe cómo hablarles a los niños.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom sabe unos cuantos trucos de magia.'\n",
      "\n",
      "sentence: 'Pídele ayuda a tu padre.'\n",
      "\n",
      "sentence: 'Le ignoré.'\n",
      "\n",
      "sentence: 'Creo que es una buena idea.'\n",
      "\n",
      "sentence: 'Quiero divertirme.'\n",
      "\n",
      "sentence: 'Si yo tuviera alas, volaría hasta ti.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Nos conocimos en la facultad.'\n",
      "\n",
      "sentence: 'No te molestes en contestar esta carta.'\n",
      "\n",
      "sentence: 'Mañana va a haber una carrera de tres millas.'\n",
      "\n",
      "sentence: 'Tengo que cerrar las ventanas.'\n",
      "\n",
      "sentence: 'Él ha estado en Hokkaido.'\n",
      "\n",
      "sentence: 'Parecía como si hubiese estado enferma.'\n",
      "\n",
      "sentence: 'Soy un buen tipo.'\n",
      "\n",
      "sentence: '¿Quieres papas fritas con eso?'\n",
      "\n",
      "sentence: '¿Por qué no te ayudó?'\n",
      "\n",
      "sentence: 'Me imagino que esta noche vas a estar muy ocupado.'\n",
      "\n",
      "sentence: 'Esto me vuelve loco.'\n",
      "\n",
      "sentence: 'Yo prefiero trabajar por mi cuenta.'\n",
      "\n",
      "sentence: 'Tengo que lustrarme los zapatos.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Lo siento, no puedo ir contigo.'\n",
      "\n",
      "sentence: 'No te vas a meter en problemas por ayudarme.'\n",
      "\n",
      "sentence: 'Había paz por todo el mundo.'\n",
      "\n",
      "sentence: 'Necesito cargar mi celular.'\n",
      "\n",
      "sentence: 'Él es muy joven.'\n",
      "\n",
      "sentence: 'Tom no corrió.'\n",
      "\n",
      "sentence: 'Su único deseo es de volver a verlo pronto.'\n",
      "\n",
      "sentence: 'El tren se retrasó una hora.'\n",
      "\n",
      "sentence: 'Tom nos engañó.'\n",
      "\n",
      "sentence: 'Él murió en el terremoto.'\n",
      "\n",
      "sentence: 'Lamento mucho lo que dije.'\n",
      "\n",
      "sentence: 'Escribid con tinta.'\n",
      "\n",
      "sentence: 'Es muy relajante.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Iremos.'\n",
      "\n",
      "sentence: 'No tenemos nada de qué hablar.'\n",
      "\n",
      "sentence: 'Mi hija quiere un gatito.'\n",
      "\n",
      "sentence: 'Pensé que habías dicho que no hacías ese tipo de cosas.'\n",
      "\n",
      "sentence: 'Él tradujo el libro del francés al inglés.'\n",
      "\n",
      "sentence: 'Tenemos algo especial para usted, señor.'\n",
      "\n",
      "sentence: 'La leche me da dolor de estómago.'\n",
      "\n",
      "sentence: 'No sabes cómo hacerlo, ¿verdad?'\n",
      "\n",
      "sentence: 'Tom se negó.'\n",
      "\n",
      "sentence: 'Harvard se fundó en 1636.'\n",
      "\n",
      "sentence: 'Tom no es el hermano de Mary. Él es su primo.'\n",
      "\n",
      "sentence: 'Tom sabía que Mary estaba con John.'\n",
      "\n",
      "sentence: 'Le gusta el jamón y los huevos.'\n",
      "\n",
      "sentence: '¿Quieres que enhebre la aguja por ti?'\n",
      "\n",
      "no word!\n",
      "sentence: 'Como principiante, Tom lo hizo bien.'\n",
      "\n",
      "sentence: 'Vamos a probar el nuevo material.'\n",
      "\n",
      "sentence: 'Cebé el anzuelo.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Deme la mitad.'\n",
      "\n",
      "sentence: 'Él recogió flores para ella.'\n",
      "\n",
      "sentence: 'Ella le ayudó.'\n",
      "\n",
      "sentence: '¡Qué estrechas son estas escaleras!'\n",
      "\n",
      "no word!\n",
      "sentence: 'No llegué a casa hasta las dos y media.'\n",
      "\n",
      "sentence: 'Todos los demás esperaban.'\n",
      "\n",
      "sentence: 'Tom es muy trabajador y digno de confianza.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom no ha vivido nunca en Boston.'\n",
      "\n",
      "sentence: 'Te aseguro que es bastante innecesario.'\n",
      "\n",
      "sentence: 'Está muy orgulloso de su motocicleta personalizada.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Mi vista está empeorando.'\n",
      "\n",
      "sentence: '¿Cuáles son de Tom?'\n",
      "\n",
      "sentence: 'Mi madre no puede venir.'\n",
      "\n",
      "sentence: 'Canta, por favor.'\n",
      "\n",
      "sentence: 'Perdí mis anteojos.'\n",
      "\n",
      "sentence: 'Después del almuerzo vimos televisión.'\n",
      "\n",
      "sentence: 'Tom le pidió a Mary que le hablara de la casa en la que vivía cuando era niña.'\n",
      "\n",
      "sentence: 'Nos gustaría escalar esa montaña.'\n",
      "\n",
      "sentence: 'Deje el café ahí para que se enfríe.'\n",
      "\n",
      "sentence: 'Si hubiese sido honesto, lo habría contratado.'\n",
      "\n",
      "sentence: '¡Entra aquí!'\n",
      "\n",
      "sentence: 'Ella murió del shock.'\n",
      "\n",
      "sentence: 'Él da muy firmemente la mano.'\n",
      "\n",
      "sentence: 'Sólo tira de la cadena.'\n",
      "\n",
      "sentence: '¿Puedo hacer un par de preguntas?'\n",
      "\n",
      "sentence: 'Es difícil de robar a un ladrón.'\n",
      "\n",
      "sentence: 'Fui a ver a su hermana la semana pasada.'\n",
      "\n",
      "sentence: 'El teléfono está sonando. Si quieres, contesto yo.'\n",
      "\n",
      "sentence: 'Púdrete, mamón.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Ella le presentó a su hermana hace más de dos años.'\n",
      "\n",
      "sentence: 'Tom tiene ojos rasgados.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Derrúmbalo.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No es una buena idea.'\n",
      "\n",
      "sentence: 'De pronto, comenzó a llover.'\n",
      "\n",
      "sentence: 'Tom conoce al esposo de María.'\n",
      "\n",
      "sentence: 'Cuando volvió en sí, estaba tirado en el parque.'\n",
      "\n",
      "sentence: 'El motor está ronroneando.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Gracias por la torta.'\n",
      "\n",
      "sentence: 'Tres horas son muy pocas para que discutamos ese asunto.'\n",
      "\n",
      "sentence: 'Me apetece beber leche.'\n",
      "\n",
      "sentence: 'A él le gusta mucho tocar la guitarra.'\n",
      "\n",
      "sentence: 'Tomás está de acuerdo.'\n",
      "\n",
      "sentence: '¿Cómo se creó el universo?'\n",
      "\n",
      "sentence: 'Estas corbatas son muy caras.'\n",
      "\n",
      "sentence: 'Tom no cree en Dios.'\n",
      "\n",
      "sentence: 'Tom heredó su riqueza.'\n",
      "\n",
      "sentence: 'Hay un banco en frente del hotel.'\n",
      "\n",
      "sentence: 'Tom se cansó de tener que pagar siempre la cuenta cada vez que salía con Mary.'\n",
      "\n",
      "sentence: 'Asegúrate de estar allí para las dos y media.'\n",
      "\n",
      "sentence: 'Los comunistas lanzaron una importante campaña militar.'\n",
      "\n",
      "sentence: 'Me compré una chaqueta sin cuello.'\n",
      "\n",
      "sentence: 'Necesito una bolsa de papel para guardarlo.'\n",
      "\n",
      "sentence: '¿Estás estudiando francés?'\n",
      "\n",
      "sentence: '¿Por qué me tomas las manos?'\n",
      "\n",
      "sentence: 'Tú siempre llegas atrasado.'\n",
      "\n",
      "sentence: 'Tom no quiere irse a casa.'\n",
      "\n",
      "sentence: 'Tú tienes que permanecer independiente.'\n",
      "\n",
      "sentence: '¿Me vas a decir que no sabés hacer un huevo duro?'\n",
      "\n",
      "sentence: 'Prefiero volar en avión.'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 'Tras mucho reflexionar, el bandido decidió confesar.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Él se giró.'\n",
      "\n",
      "sentence: '¿No hay alguna otra cosa?'\n",
      "\n",
      "sentence: '¿Es éste el autobús para Oxford?'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom ahora está en algún lugar en Australia.'\n",
      "\n",
      "sentence: 'Deberías haber estado aquí.'\n",
      "\n",
      "sentence: 'Tomás volvió a llamarla.'\n",
      "\n",
      "sentence: 'La policia está buscando sospechosos.'\n",
      "\n",
      "sentence: '¿Coméis carne?'\n",
      "\n",
      "no word!\n",
      "sentence: 'Yo soy de Noruega.'\n",
      "\n",
      "sentence: 'Esto es lo mejor que se pone, chicos.'\n",
      "\n",
      "sentence: 'Sabía que Tom no era bueno.'\n",
      "\n",
      "sentence: 'Mañana voy a ir a verla.'\n",
      "\n",
      "sentence: 'Eres un doctor.'\n",
      "\n",
      "sentence: 'Tomás me estuvo mensajeando.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Soñé que me estaba comiendo la tarta de bodas de mi nieta.'\n",
      "\n",
      "sentence: 'Mañana voy a Boston.'\n",
      "\n",
      "sentence: '¿Conoce Tom a Mary?'\n",
      "\n",
      "sentence: '¿Qué libro necesita?'\n",
      "\n",
      "sentence: 'Somos profesores.'\n",
      "\n",
      "sentence: 'Yo soy el que recibió la paliza.'\n",
      "\n",
      "sentence: 'Discúlpeme. No pensé que fuera su asiento.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Ella siempre luce pálida.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Hay mucho que hacer.'\n",
      "\n",
      "sentence: '¿Estás enamorada de Tom?'\n",
      "\n",
      "sentence: 'Estudié francés hace mucho tiempo, pero ahora todo lo que recuerdo es \"bonjour\".'\n",
      "\n",
      "no word!\n",
      "sentence: 'Él no es como nosotros.'\n",
      "\n",
      "sentence: 'Tom conserva un par de zapatos extra en el maletero de su auto.'\n",
      "\n",
      "sentence: 'Tom estaba chismorreando.'\n",
      "\n",
      "sentence: 'Cada vez que llueve, el techo gotea.'\n",
      "\n",
      "sentence: '¿Podrías echarle un vistazo a este documento?'\n",
      "\n",
      "sentence: 'Tom cerró la boca.'\n",
      "\n",
      "sentence: 'Estoy de vuelta en Boston.'\n",
      "\n",
      "sentence: 'Mary es una persona cálida y bondadosa, pero Tom es frío y distante.'\n",
      "\n",
      "no word!\n",
      "sentence: '¿Por qué no vas en mi lugar?'\n",
      "\n",
      "sentence: '¿Me estás bromeando?'\n",
      "\n",
      "sentence: 'Ella cantó suavemente la canción.'\n",
      "\n",
      "sentence: '¿A quién está buscando Tom?'\n",
      "\n",
      "sentence: 'Este edificio está hecho de piedra.'\n",
      "\n",
      "sentence: 'Me gustaría abrir una cuenta de ahorros.'\n",
      "\n",
      "sentence: 'Ella le compró un coche, pero él no tenía carnet de conducir, de modo que no podía llevarlo a ninguna parte.'\n",
      "\n",
      "sentence: 'Tan pronto como pueda costearme comprar una casa, lo haré.'\n",
      "\n",
      "sentence: 'Si mañana está lindo, jugaremos al béisbol.'\n",
      "\n",
      "sentence: 'Ayer me dijeron que me veía como Kohei Tanaka.'\n",
      "\n",
      "no word!\n",
      "sentence: '¿Puede ser cierto?'\n",
      "\n",
      "sentence: '¿Está limpio el lugar?'\n",
      "\n",
      "sentence: 'Póngase en mi lugar.'\n",
      "\n",
      "sentence: 'No creo que alguna vez vaya a sonar como un hablante nativo, y en realidad no creo que lo necesite.'\n",
      "\n",
      "sentence: 'Él parecía decepcionado de los resultados.'\n",
      "\n",
      "sentence: 'Tom vive a 10 millas de la frontera con Canadá.'\n",
      "\n",
      "sentence: 'Casi estás en lo cierto.'\n",
      "\n",
      "sentence: 'Por favor, no vuelvas a mirar hacia aquí.'\n",
      "\n",
      "sentence: 'He visto muchas veces a Tom en la televisión.'\n",
      "\n",
      "sentence: 'Se está poniendo un abrigo.'\n",
      "\n",
      "sentence: '¿Está fuera Tom?'\n",
      "\n",
      "sentence: 'Tom me pidió que fuera más atento.'\n",
      "\n",
      "sentence: 'Tom parece divertirse provocando discusiones.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Estoy engordando porque como muchos dulces.'\n",
      "\n",
      "no word!\n",
      "sentence: 'La función del corazón es bombear sangre.'\n",
      "\n",
      "sentence: '¿Deseas hacer cualquier otra operación?'\n",
      "\n",
      "sentence: 'Somos hermanos.'\n",
      "\n",
      "sentence: 'Necesito verle de nuevo.'\n",
      "\n",
      "sentence: 'Cuando ves televisión o escuchas a la radio, la música que oyes a menudo es de origen africano.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No quiero levantarme.'\n",
      "\n",
      "sentence: 'Tom no sabe lo que está haciendo, ¿verdad?'\n",
      "\n",
      "sentence: '¿De casualidad te sabes su nombre?'\n",
      "\n",
      "sentence: '¿Sabe qué significa UNESCO?'\n",
      "\n",
      "no word!\n",
      "sentence: 'Salió del coche.'\n",
      "\n",
      "sentence: 'Él haló la cuerda.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom vio lo que hizo Mary.'\n",
      "\n",
      "sentence: 'Es una buena vista desde aquí.'\n",
      "\n",
      "sentence: 'Nosotros los humanos tenemos una grandiosa manera de retorcer los hechos para adecuarlos a nuestra conclusión tan pronto hayamos hecho alguna.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Mary, Tom quiere matarte.'\n",
      "\n",
      "sentence: 'Solo necesito aire.'\n",
      "\n",
      "sentence: 'Sabes lo que tienes que hacer.'\n",
      "\n",
      "sentence: 'Compré el auto.'\n",
      "\n",
      "sentence: 'Hice lo que pude'\n",
      "\n",
      "sentence: 'Aquí no hay azúcar.'\n",
      "\n",
      "sentence: 'Ellos vieron a un gato escalando en árbol.'\n",
      "\n",
      "sentence: '¿Has abierto esta puerta alguna vez?'\n",
      "\n",
      "sentence: 'Mañana es feriado.'\n",
      "\n",
      "sentence: '¿Me podrías llamar más tarde por favor?'\n",
      "\n",
      "sentence: 'Tienen vino.'\n",
      "\n",
      "sentence: 'Él resolvió cada problema.'\n",
      "\n",
      "sentence: 'A Tomás se le da muy bien el ajedrez.'\n",
      "\n",
      "sentence: 'No tengo nada para darte.'\n",
      "\n",
      "sentence: 'Como ya era tarde, me fui a dormir.'\n",
      "\n",
      "sentence: 'Aún no puedo decirte la respuesta a eso.'\n",
      "\n",
      "sentence: 'Quiero hacer un poco de ejercicio.'\n",
      "\n",
      "sentence: 'El tío Tom es el hermano de mi madre.'\n",
      "\n",
      "sentence: 'Las cosas están a punto de ponerse feas.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Él empezó a almorzar.'\n",
      "\n",
      "sentence: 'Tom fue a la cárcel por vender drogas.'\n",
      "\n",
      "sentence: 'Tom y Mary se subieron a sus carros.'\n",
      "\n",
      "sentence: 'Su llegada animó la fiesta.'\n",
      "\n",
      "sentence: 'Eso puede pasar el lunes.'\n",
      "\n",
      "sentence: 'Estoy comprometida.'\n",
      "\n",
      "sentence: 'Él es el menos probable que venga.'\n",
      "\n",
      "sentence: 'Pienso que es moralmente incorrecto comer personas.'\n",
      "\n",
      "sentence: 'Ellos viajaron juntos.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Ellos atacarán.'\n",
      "\n",
      "sentence: 'Ella estaba avergonzada del comportamiento de sus niños.'\n",
      "\n",
      "sentence: '¿Qué hay de nosotros?'\n",
      "\n",
      "sentence: 'El barco se hunde.'\n",
      "\n",
      "sentence: 'Esa caja es muy pesada para cargarla.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom disparó primero.'\n",
      "\n",
      "sentence: 'Ahora da un paso atrás.'\n",
      "\n",
      "sentence: 'He estado estudiando inglés durante cinco años.'\n",
      "\n",
      "sentence: '¿Dónde te quitaste los guantes?'\n",
      "\n",
      "sentence: 'Luxemburgo es un pequeño país.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Si toma algunos antibióticos y duerme, ella se encontrará mejor.'\n",
      "\n",
      "sentence: 'Él dudó antes de responder.'\n",
      "\n",
      "sentence: 'Dejó el libro en la mesa.'\n",
      "\n",
      "sentence: 'Asegúrate de mandarnos una nota tan pronto llegues a Londres.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Creo que es perseguir un imposible.'\n",
      "\n",
      "sentence: 'Eso es lo que crees tú.'\n",
      "\n",
      "sentence: 'Helen Keller era sorda y ciega.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Vi a un hombre entrar a la habitación.'\n",
      "\n",
      "sentence: '¿Por qué Tom no habla?'\n",
      "\n",
      "sentence: 'Tom no es sincero.'\n",
      "\n",
      "sentence: '¿Dónde están?'\n",
      "\n",
      "sentence: 'Tom estaba intentando protegerte.'\n",
      "\n",
      "sentence: '¿Tom está en problemas otra vez?'\n",
      "\n",
      "sentence: 'Él llevaba un esmoquin.'\n",
      "\n",
      "sentence: 'Aunque él sabía la verdad, no nos dijo nada.'\n",
      "\n",
      "sentence: 'Tú eres aquel.'\n",
      "\n",
      "sentence: 'Sé que probablemente estés enfadada acerca de lo que dije ayer.'\n",
      "\n",
      "sentence: 'En verdad no te conozco.'\n",
      "\n",
      "sentence: 'El río Nilo es el más largo del mundo.'\n",
      "\n",
      "sentence: 'La iPad sería la solución perfecta para mí si pudiera mostrar correctamente las páginas web que tienen contenidos con Flash.'\n",
      "\n",
      "sentence: 'Nosotros solíamos dar una caminata antes del desayuno.'\n",
      "\n",
      "sentence: 'Tenemos que ir al colegio.'\n",
      "\n",
      "sentence: 'Tom tiene una reunión todos los lunes por la tarde.'\n",
      "\n",
      "sentence: 'Las pruebas de mediado de año están a la vuelta de la esquina.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Mientras haya esperanza, existe la posibilidad.'\n",
      "\n",
      "sentence: 'Sé que es difícil hablar al respecto.'\n",
      "\n",
      "sentence: 'Desconozco si Tom nadará o no.'\n",
      "\n",
      "sentence: 'Ya he comido.'\n",
      "\n",
      "sentence: 'Aprende a mantener los tiempos.'\n",
      "\n",
      "sentence: 'No tenía ni idea de quién era.'\n",
      "\n",
      "sentence: 'Es tu decisión.'\n",
      "\n",
      "sentence: 'Mi padre está ocupado.'\n",
      "\n",
      "sentence: '¿Has tenido nauseas alguna vez en un tren?'\n",
      "\n",
      "sentence: 'Necesito estar aquí por otras cuatro horas.'\n",
      "\n",
      "sentence: 'El niño lleva un murciélago bajo el brazo.'\n",
      "\n",
      "sentence: 'Más de un amigo mío no sabe nadar.'\n",
      "\n",
      "sentence: 'La anciana subió las escaleras con dificultad.'\n",
      "\n",
      "sentence: '¿Devolviste el libro de Tom?'\n",
      "\n",
      "sentence: 'No le digas a mi esposa, por favor.'\n",
      "\n",
      "sentence: 'No puedo hacerlo sola.'\n",
      "\n",
      "sentence: 'Tom no corrió lo suficientemente rápido para alcanzar el bus.'\n",
      "\n",
      "sentence: 'Ya veo por qué no te gusta Tom.'\n",
      "\n",
      "sentence: 'Estas galletas tienen forma de estrella.'\n",
      "\n",
      "sentence: 'Tengo que arreglarlo.'\n",
      "\n",
      "sentence: 'Te voy a contar una historia.'\n",
      "\n",
      "sentence: 'No necesito vigilar a Tom todo el tiempo.'\n",
      "\n",
      "sentence: 'El teléfono empezó a sonar.'\n",
      "\n",
      "sentence: 'Tom no sabe nada acerca del pasado de Mary.'\n",
      "\n",
      "sentence: 'Las matemáticas son una materia fácil para mí.'\n",
      "\n",
      "sentence: 'Él levantó la mano para hacer una pregunta.'\n",
      "\n",
      "sentence: 'Yo no tengo nada que ver con ese crimen.'\n",
      "\n",
      "sentence: 'Comencé a escribir un libro.'\n",
      "\n",
      "sentence: 'Algo así no puede ocurrir en Japón.'\n",
      "\n",
      "sentence: 'Tomás abrió la jaula.'\n",
      "\n",
      "sentence: 'Olvidé que hoy era sábado.'\n",
      "\n",
      "sentence: 'El gato es café.'\n",
      "\n",
      "sentence: 'El sudor permite regular la temperatura corporal.'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 'Te mostraré la ciudad.'\n",
      "\n",
      "sentence: 'Debe su éxito a sus padres.'\n",
      "\n",
      "sentence: 'Esa no es mi línea.'\n",
      "\n",
      "sentence: 'Pagué la cuenta.'\n",
      "\n",
      "sentence: 'Es hora de que los niños vayan a la cama.'\n",
      "\n",
      "sentence: 'Tom bebe como un pez.'\n",
      "\n",
      "sentence: 'Ella me saludó con una sonrisa.'\n",
      "\n",
      "sentence: 'Todavía no hemos llamado a la policía.'\n",
      "\n",
      "sentence: 'Adoptaron a la niña pequeña.'\n",
      "\n",
      "sentence: 'Hervimos agua para hacer fideos.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom no se da cuenta de lo afortunado que es.'\n",
      "\n",
      "sentence: 'Ojalá hubiera aprendido esto en el colegio.'\n",
      "\n",
      "sentence: 'Yo estuve aquí todo el tiempo.'\n",
      "\n",
      "sentence: 'El bolígrafo está roto.'\n",
      "\n",
      "sentence: 'Estaba parado detrás de la puerta.'\n",
      "\n",
      "sentence: 'Tom miró a su alrededor frenéticamente.'\n",
      "\n",
      "no word!\n",
      "sentence: 'El tren paró en la estación.'\n",
      "\n",
      "sentence: 'Puedo ser tu mejor amiga o tu peor enemiga.'\n",
      "\n",
      "sentence: 'Ellos quieren saber cuál es tu plan.'\n",
      "\n",
      "sentence: 'Tom era muy atractivo cuando era joven.'\n",
      "\n",
      "sentence: 'Tom no tiene que pagar nada.'\n",
      "\n",
      "sentence: 'Mantén tus manos limpias.'\n",
      "\n",
      "sentence: 'Le pregunté sin andarme con rodeos.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No le hagas caso.'\n",
      "\n",
      "sentence: 'Tom es un excelente jugador.'\n",
      "\n",
      "sentence: 'Él tiene muchos sellos extranjeros, sin mencionar los japoneses.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No tengo idea de qué significa esto.'\n",
      "\n",
      "sentence: 'Estaba hambriento y sediento.'\n",
      "\n",
      "sentence: 'Él taló un cerezo.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Consígueme mis píldoras.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom es sólo un poquito más bajo que yo.'\n",
      "\n",
      "sentence: '¿Tocas la batería?'\n",
      "\n",
      "sentence: 'Tom probó la comida que había preparado Mary.'\n",
      "\n",
      "sentence: 'Puede que nieve esta noche.'\n",
      "\n",
      "sentence: 'Almorcemos fuera.'\n",
      "\n",
      "sentence: 'Me gustaría retirar algún dinero en efectivo.'\n",
      "\n",
      "sentence: 'El gato saltó sobre la mesa.'\n",
      "\n",
      "sentence: 'Contacté a mis padres.'\n",
      "\n",
      "sentence: 'Solo somos amigos.'\n",
      "\n",
      "sentence: 'Ten cuidado con ese cuchillo.'\n",
      "\n",
      "sentence: 'El camino va paralelo al río.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Ella era una mujer de mediana edad.'\n",
      "\n",
      "sentence: '¿Qué conoces de Australia?'\n",
      "\n",
      "sentence: 'Las cobras están siempre muy alerta.'\n",
      "\n",
      "no word!\n",
      "sentence: 'A él le gusta sentarse y jugar videojuegos todo el día.'\n",
      "\n",
      "sentence: 'Suelo oírla tocar el piano.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No recuerdo haberte visto desde hace dos años.'\n",
      "\n",
      "sentence: 'Me gustaría que este carro sea reparado lo más pronto posible.'\n",
      "\n",
      "sentence: 'Sin la capa de ozono, estaríamos en peligro.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Debería haber ido a la reunión de ayer.'\n",
      "\n",
      "sentence: 'Ella se quedó ahí por varios días.'\n",
      "\n",
      "sentence: 'Mis amigos dicen que hablo mejor en francés cuando estoy borracho.'\n",
      "\n",
      "sentence: 'Ella está orgullosa de que su padre sea rico.'\n",
      "\n",
      "sentence: 'Tomás no puede ganar.'\n",
      "\n",
      "sentence: 'Ella pagará el máximo de cincuenta dólares.'\n",
      "\n",
      "sentence: 'Ella no sabe cocinar bien.'\n",
      "\n",
      "sentence: 'A Tom le gustan los frijoles.'\n",
      "\n",
      "sentence: 'Tom se cambió de ropa.'\n",
      "\n",
      "sentence: 'Para perder peso tienes que comer menos dulces.'\n",
      "\n",
      "sentence: 'A veces me quedo sin dinero.'\n",
      "\n",
      "sentence: '¿No crees que es extraño?'\n",
      "\n",
      "sentence: 'Él nos está entreteniendo.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Ella nos enseñó la foto de su madre.'\n",
      "\n",
      "sentence: 'Dime cuál elegir.'\n",
      "\n",
      "sentence: 'Tom te está esperando adentro.'\n",
      "\n",
      "sentence: 'Mi hermano nada bien.'\n",
      "\n",
      "sentence: 'Nos rendimos demasiado pronto.'\n",
      "\n",
      "sentence: 'Tom no te culparía.'\n",
      "\n",
      "sentence: 'No vi a nadie aparte de ti.'\n",
      "\n",
      "sentence: 'Tom necesita algo más de descanso.'\n",
      "\n",
      "sentence: '¿Qué cenaste anoche?'\n",
      "\n",
      "no word!\n",
      "sentence: 'No sabes lo cansado que estoy de todas estas quejas.'\n",
      "\n",
      "sentence: 'Mis amigos no saben dónde estoy.'\n",
      "\n",
      "sentence: 'Tom actualmente reside en Boston.'\n",
      "\n",
      "no word!\n",
      "sentence: '¿Está orgullosa de su padre?'\n",
      "\n",
      "sentence: '¿Cuál es tu tipo de música favorita?'\n",
      "\n",
      "sentence: 'Mi deporte favorito es el fútbol.'\n",
      "\n",
      "sentence: 'Me ignorabas.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Ella tenía conocimiento de su mirada.'\n",
      "\n",
      "sentence: '¿Qué tan mal me veo?'\n",
      "\n",
      "sentence: 'Ser mujer es difícil. Hay que pensar como hombre, actuar como una dama, verse como una niña y trabajar como caballo.'\n",
      "\n",
      "sentence: 'Oí que una mujer apuñaló a un hombre por comerse su almuerzo.'\n",
      "\n",
      "sentence: 'Me quedé mudo de la emoción.'\n",
      "\n",
      "sentence: 'No hay luces.'\n",
      "\n",
      "sentence: 'Me he deprimido profundamente.'\n",
      "\n",
      "sentence: 'El perro de Tom es marrón.'\n",
      "\n",
      "sentence: 'Cenan a medianoche.'\n",
      "\n",
      "sentence: 'Cierra la puerta detrás de ti.'\n",
      "\n",
      "sentence: 'Es muy bonita pero no tiene atractivo.'\n",
      "\n",
      "sentence: 'Por supuesto que es ilegal.'\n",
      "\n",
      "sentence: '¿Fuiste a El Cairo o a Alejandría?'\n",
      "\n",
      "no word!\n",
      "sentence: 'Hoy te ves pálido.'\n",
      "\n",
      "sentence: 'No puedo ayudarte con esto.'\n",
      "\n",
      "sentence: '¿Estaba su madre mirando a las niñas?'\n",
      "\n",
      "sentence: '¿Estás seguro de querer ir?'\n",
      "\n",
      "sentence: '¿Dónde has ido? \"He ido a la estación a despedir a un amigo.\"'\n",
      "\n",
      "sentence: 'He estado en contacto permanente con Tom.'\n",
      "\n",
      "sentence: 'Te echaba mucho de menos.'\n",
      "\n",
      "sentence: 'Si volviera a nacer otra vez, sería músico.'\n",
      "\n",
      "sentence: 'Tuve que dispararle a mi caballo.'\n",
      "\n",
      "sentence: 'Mi madre me ama.'\n",
      "\n",
      "sentence: 'Mi tío está enfadado.'\n",
      "\n",
      "sentence: 'Después viene su turno.'\n",
      "\n",
      "sentence: '¿Por qué no te puedes apresurar?'\n",
      "\n",
      "sentence: 'Me temo que no hay mucho que pueda hacer para ayudar.'\n",
      "\n",
      "sentence: 'Creo que estamos listos para ir allí.'\n",
      "\n",
      "sentence: 'La tormenta no mostró señales de abatirse.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Ya pasó lo peor.'\n",
      "\n",
      "sentence: 'Quiero que entiendas lo que estoy tratando de decir.'\n",
      "\n",
      "sentence: 'La chica habla muy bien inglés.'\n",
      "\n",
      "sentence: 'Me gusta más el invierno que el verano.'\n",
      "\n",
      "sentence: '¿Dónde está la clase de Tom?'\n",
      "\n",
      "sentence: 'Tuvimos suerte.'\n",
      "\n",
      "sentence: 'Tom tuvo problemas para resolver la situación.'\n",
      "\n",
      "sentence: 'El auto de mi padre es hecho en Italia.'\n",
      "\n",
      "sentence: 'Aunque a veces tímido, se desenvolvía con audacia en otros menesteres.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom era indudablemente de fiar.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No puedo creer que él hiciera eso.'\n",
      "\n",
      "sentence: 'Ven a las dos.'\n",
      "\n",
      "sentence: 'Digamos que no me sorprendí.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Espero que todos tus sueños se cumplan.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Este libro es más pequeño.'\n",
      "\n",
      "sentence: 'Tom estaba muy borracho.'\n",
      "\n",
      "sentence: 'Pensé que era hora de almorzar.'\n",
      "\n",
      "sentence: 'Estoy convencida de que Tom no nos está diciendo todo.'\n",
      "\n",
      "sentence: 'Tom estuvo todo el día reunido.'\n",
      "\n",
      "sentence: 'No estoy acostumbrada a hablar en público.'\n",
      "\n",
      "sentence: 'Tom no está muy feliz.'\n",
      "\n",
      "sentence: 'Tengo que tomar algo para mi resfriado.'\n",
      "\n",
      "sentence: 'Elige con cuidado.'\n",
      "\n",
      "sentence: 'Eres una linda chica.'\n",
      "\n",
      "sentence: 'Tom quería cambiar el tema.'\n",
      "\n",
      "sentence: 'Quiero hablarte, Tom.'\n",
      "\n",
      "sentence: 'Nadie me escucha.'\n",
      "\n",
      "sentence: 'Esto se ve estupendo.'\n",
      "\n",
      "sentence: 'Estoy estudiando inglés.'\n",
      "\n",
      "sentence: 'Tom volvió a acomodarse en su camión.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Ella es una profesora muy buena.'\n",
      "\n",
      "sentence: 'Tom adivinó bien.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom quiere saber cuándo Mary irá de compras.'\n",
      "\n",
      "sentence: 'Ustedes tres están arrestadas.'\n",
      "\n",
      "sentence: 'Tom se hizo médico.'\n",
      "\n",
      "sentence: 'Aquellos que viven en casas de cristal no deberían tirar piedras.'\n",
      "\n",
      "sentence: 'No me quiero perder el bus.'\n",
      "\n",
      "sentence: 'Es un buen vino.'\n",
      "\n",
      "sentence: '¿Estaba Tom con Mary?'\n",
      "\n",
      "sentence: 'Tom estaba a punto de tomar un baño cuando sonó el timbre.'\n",
      "\n",
      "sentence: '¿Puedo hacer algo para ayudarte?'\n",
      "\n",
      "sentence: 'Tengo que pasar este examen.'\n",
      "\n",
      "sentence: 'Tomás siempre es muy agradable.'\n",
      "\n",
      "sentence: 'Un momento.'\n",
      "\n",
      "sentence: 'No entres a mi pieza sin golpear.'\n",
      "\n",
      "sentence: 'No estoy acostumbrada a hablar en público.'\n",
      "\n",
      "sentence: 'El parecido es asombroso.'\n",
      "\n",
      "sentence: 'Deberíais escuchar a Tom.'\n",
      "\n",
      "sentence: '¿Dónde está la salida de emergencia?'\n",
      "\n",
      "sentence: 'Él siempre va uno o dos pasos adelante del tiempo.'\n",
      "\n",
      "sentence: 'Ya has hecho demasiado.'\n",
      "\n",
      "sentence: 'Tom quería adelgazar.'\n",
      "\n",
      "sentence: '¿Por qué Tom me odia?'\n",
      "\n",
      "sentence: 'Pruébalo.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Hierve un poco de agua.'\n",
      "\n",
      "sentence: 'Tom todavía no encontró lo que está buscando.'\n",
      "\n",
      "sentence: 'Yo pensaba que él vendría.'\n",
      "\n",
      "sentence: 'Siento interrumpirte cuando hablas.'\n",
      "\n",
      "sentence: 'No fue un sueño.'\n",
      "\n",
      "sentence: 'Mi cuñado es un madero.'\n",
      "\n",
      "sentence: 'No tienes que venir aquí todos los días.'\n",
      "\n",
      "sentence: '¿Podemos conversar?'\n",
      "\n",
      "sentence: 'Cumplí veinte años.'\n",
      "\n",
      "sentence: 'A él le gusta desarmar aparatos eléctricos.'\n",
      "\n",
      "no word!\n",
      "sentence: '¿Recibiste el paquete que te mandé?'\n",
      "\n",
      "sentence: 'El policía culpó al taxista por el accidente.'\n",
      "\n",
      "sentence: 'Tengo dos cámaras.'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 'Mi padre me ayudó con los deberes.'\n",
      "\n",
      "sentence: 'No estoy nada cansado.'\n",
      "\n",
      "sentence: '¿Tiene seguro médico?'\n",
      "\n",
      "sentence: 'Encontrar una solución óptima demorará un tiempo.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Algunos estaban borrachos la mayor parte del tiempo.'\n",
      "\n",
      "sentence: 'Cristóbal Colón descubrió América.'\n",
      "\n",
      "sentence: 'A finales de agosto, las fuerzas aliadas tomaron París.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Vendré a verte el domingo a las tres de la tarde.'\n",
      "\n",
      "sentence: 'Quiero que seas mi socio.'\n",
      "\n",
      "sentence: 'Ella es amable.'\n",
      "\n",
      "sentence: 'No está de acuerdo con su familia.'\n",
      "\n",
      "sentence: 'Está ocurriendo esta noche.'\n",
      "\n",
      "sentence: 'Deberías haber llamado a la policía.'\n",
      "\n",
      "sentence: 'Eres la última persona que habría pensado encontrar aquí.'\n",
      "\n",
      "sentence: 'Esto no es un accidente.'\n",
      "\n",
      "sentence: 'Habéis venido demasiado pronto.'\n",
      "\n",
      "sentence: 'Dejó de buscar la perla.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Le gusta cazar.'\n",
      "\n",
      "sentence: 'No te olvides de despertarme mañana por la mañana.'\n",
      "\n",
      "sentence: 'Tom decidió no decirle a María nada de lo que Juan había hecho.'\n",
      "\n",
      "sentence: 'Les di mil yenes a cada uno.'\n",
      "\n",
      "sentence: 'Pensé que habías dicho que Tom había muerto.'\n",
      "\n",
      "sentence: 'Esta mañana llegué tarde a la escuela.'\n",
      "\n",
      "sentence: 'El bebé está llorando.'\n",
      "\n",
      "sentence: 'Me quedé atónito.'\n",
      "\n",
      "sentence: 'Me gustaría tomar al menos una botella más de cerveza antes de ir a casa.'\n",
      "\n",
      "sentence: 'Una batidora te permite mezclar comidas diferentes.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tom le regaló un diccionario de francés a Mary.'\n",
      "\n",
      "sentence: 'Caminaba a paso rápido.'\n",
      "\n",
      "sentence: 'Realmente funciona.'\n",
      "\n",
      "sentence: 'Los guardias dispersaron a la multitud.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No tengo un mango.'\n",
      "\n",
      "sentence: 'Voy a hacer una pasantía en una empresa local.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Dijo que irá a Estados Unidos.'\n",
      "\n",
      "sentence: 'El policía tenía una curda encima...'\n",
      "\n",
      "no word!\n",
      "sentence: 'Te dije que te quedaras quieta.'\n",
      "\n",
      "sentence: 'Tom tiene que pagar por todo.'\n",
      "\n",
      "sentence: '¿Qué necesita decir Tom para que Mary lo perdone?'\n",
      "\n",
      "sentence: 'Ella irá a Francia la semana próxima.'\n",
      "\n",
      "sentence: 'Tom y Mary están muy enamorados.'\n",
      "\n",
      "sentence: 'Ella estuvo inconsciente por tres días.'\n",
      "\n",
      "sentence: 'Sé lo que le pasó a Tom.'\n",
      "\n",
      "sentence: 'Tom preparó una torta para el cumpleaños de Mary.'\n",
      "\n",
      "sentence: 'Estoy almorzando con mi hermana ahora.'\n",
      "\n",
      "sentence: '¿Por qué quieres esto?'\n",
      "\n",
      "sentence: 'Los estudiantes se levantaron uno por uno y se presentaron.'\n",
      "\n",
      "sentence: 'Están hechos un manojo de nervios.'\n",
      "\n",
      "sentence: 'El ruido del tráfico denso me mantuvo toda la noche despierto.'\n",
      "\n",
      "no word!\n",
      "sentence: 'El gato me espantó.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Es ella.'\n",
      "\n",
      "sentence: 'Él sorprendió a su adversario.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Ayer me encontré con Mary.'\n",
      "\n",
      "sentence: '¿Qué prefieres, las manzanas o los plátanos?'\n",
      "\n",
      "sentence: 'Es italiano de nacimiento.'\n",
      "\n",
      "sentence: 'Creo que Tom no tiene la capacidad de resolver el problema.'\n",
      "\n",
      "sentence: 'No hablo hebreo.'\n",
      "\n",
      "sentence: 'Este es mi colegio.'\n",
      "\n",
      "sentence: '¿Qué más quiere Tom?'\n",
      "\n",
      "sentence: 'Parece estar muy feliz.'\n",
      "\n",
      "sentence: 'La estás cagando.'\n",
      "\n",
      "sentence: 'Tom no esperaba eso.'\n",
      "\n",
      "sentence: 'No puedo mentirte.'\n",
      "\n",
      "sentence: 'No sé qué haremos.'\n",
      "\n",
      "sentence: 'No puedes ser amigo de todos.'\n",
      "\n",
      "sentence: 'No estoy segura de que quiera el trabajo.'\n",
      "\n",
      "sentence: '¿Qué puedes hacer por mi?'\n",
      "\n",
      "sentence: 'Muchos estudiantes buscan trabajos a tiempo parcial.'\n",
      "\n",
      "no word!\n",
      "sentence: '¿Cómo lo sabes?'\n",
      "\n",
      "sentence: 'Lea estas instrucciones.'\n",
      "\n",
      "sentence: 'Se necesita una llave para abrir la caja.'\n",
      "\n",
      "sentence: 'Pregúntame mañana.'\n",
      "\n",
      "sentence: 'El dinero no lo es todo, pero si no tienes dinero no puedes hacer nada.'\n",
      "\n",
      "sentence: '¿Qué me aconsejas hacer?'\n",
      "\n",
      "sentence: 'No deberías usar ropa ajustada si estás embarazada.'\n",
      "\n",
      "sentence: 'Los dos niños empezaron a culparse el uno al otro.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Ella vivió allí durante muchos años.'\n",
      "\n",
      "sentence: 'Él no es el tipo más listo de la clase.'\n",
      "\n",
      "sentence: 'Esta no será la última vez.'\n",
      "\n",
      "sentence: 'Él acaba de comprarse un coche usado.'\n",
      "\n",
      "sentence: 'Después de conferenciar varias horas hicieron públicos los acuerdos.'\n",
      "\n",
      "no word!\n",
      "sentence: 'No puedo creer que Tom no venga.'\n",
      "\n",
      "sentence: '¿Qué te parecería una taza de té u otra cosa, si es que no estás apurado?'\n",
      "\n",
      "no word!\n",
      "sentence: 'El millonario tenía la intención de adquirir la obra maestra sin importar lo que costara.'\n",
      "\n",
      "sentence: 'Le daré todo lo que necesite.'\n",
      "\n",
      "sentence: 'Las negociaciones naufragaron.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Él ha traicionado a sus amigos por dinero.'\n",
      "\n",
      "sentence: 'Vamos a tener un bebé.'\n",
      "\n",
      "sentence: 'Tom parece preocupado.'\n",
      "\n",
      "sentence: 'Continúe su análisis.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Él suele ser arrogante.'\n",
      "\n",
      "sentence: 'Tom tiene un fuerte resfriado.'\n",
      "\n",
      "sentence: 'Tom no tiene tiempo para ayudarte.'\n",
      "\n",
      "sentence: 'Querría un poco de queso.'\n",
      "\n",
      "sentence: 'No podría haberlo expresado mejor.'\n",
      "\n",
      "sentence: '¿Por qué estás tan seguro de que Tom es canadiense?'\n",
      "\n",
      "sentence: 'El maestro le leyó un párrafo de la Biblia a la clase.'\n",
      "\n",
      "sentence: 'Tom fue herido.'\n",
      "\n",
      "sentence: 'Tu tienes prohibido fumar aquí.'\n",
      "\n",
      "sentence: 'Quiero estar contigo pase lo que pase.'\n",
      "\n",
      "sentence: 'Todos miramos por la ventana.'\n",
      "\n",
      "sentence: 'No podía dar otra mordida.'\n",
      "\n",
      "sentence: 'Un doctor puede enterrar sus errores, pero un arquitecto solo puede sugerirle a su cliente plantar enredaderas.'\n",
      "\n",
      "no word!\n",
      "sentence: '¿Cuál es tu desayuno preferido?'\n",
      "\n",
      "sentence: 'La temperatura bajó.'\n",
      "\n",
      "sentence: 'No salí a ningún lado porque tú me dijiste que no lo hiciera.'\n",
      "\n",
      "sentence: 'Tom alegó ser el hijo de Mary.'\n",
      "\n",
      "sentence: 'Los cables transmiten la electricidad.'\n",
      "\n",
      "sentence: 'Él rechazó su solicitud de un día libre.'\n",
      "\n",
      "sentence: 'Por favor, ¿podría firmar este documento?'\n",
      "\n",
      "sentence: 'He oído que eres una buena jugadora de tenis.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tomo vitaminas todos los días.'\n",
      "\n",
      "sentence: 'Salió de la habitación.'\n",
      "\n",
      "sentence: '¿Tomás estaba aquí cuando pasó?'\n",
      "\n",
      "sentence: 'Pasé toda la tarde tratando de encontrar mis llaves.'\n",
      "\n",
      "sentence: 'Solo quería decirte que me he encontrado con Tom esta mañana.'\n",
      "\n",
      "sentence: '¿Crees que es justo?'\n",
      "\n",
      "sentence: '¡Llama a mi esposo!'\n",
      "\n",
      "sentence: 'Él estaba de buen humor.'\n",
      "\n",
      "sentence: 'Tengo ganas de salir hoy en lugar de quedarme en casa.'\n",
      "\n",
      "sentence: 'Rendirse no es la respuesta.'\n",
      "\n",
      "sentence: 'Nosotros comemos langostas sólo en ocasiones especiales.'\n",
      "\n",
      "no word!\n",
      "sentence: 'Tomás volverá pronto.'\n",
      "\n",
      "sentence: 'Esta casa necesita una mano de pintura.'\n",
      "\n",
      "sentence: 'Mi padre está ocupado escribiendo cartas.'\n",
      "\n",
      "sentence: 'Te veré mañana en la biblioteca.'\n",
      "\n",
      "sentence: 'Él me dejó esperando.'\n",
      "\n",
      "sentence: 'La profesora la trató como una más de sus estudiantes.'\n",
      "\n",
      "sentence: '¿Tiene bebidas sin alcohol?'\n"
     ]
    }
   ],
   "source": [
    "# test dataset 파일 불러오기\n",
    "testdata = '../dataset/test/test_data.txt'\n",
    "result_path = '../outputs/supermodel'\n",
    "start_row = 2\n",
    "\n",
    "# # 엑셀 파일 불러오기\n",
    "# wb = openpyxl.load_workbook('TQE(5-Epoch).axlsx')\n",
    "# \n",
    "# # 엑셀 파일의 시트 활성화\n",
    "# sheet1 = wb['real']\n",
    "\n",
    "f = open(testdata, 'r')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "f = open(result_path + '/hpys.txt', 'w')\n",
    "\n",
    "for sentence in lines:\n",
    "    result = translate(sentence)\n",
    "    if result == 'no word':\n",
    "        f.write('no word\\n')\n",
    "    else:\n",
    "        f.write(result + '\\n')\n",
    "        \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nmt_with_attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "recur_esb",
   "language": "python",
   "name": "recur_esb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
